{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Assignment 2 - CNN & ResNet_sig.ipynb","provenance":[{"file_id":"1kyFRtM70oZ28ERx4ey5Qd4aLw_AR7gRx","timestamp":1633993192817}],"collapsed_sections":[]},"interpreter":{"hash":"a47990de418dedd5e5850a5cbe3fff5766d2f22f31c561e10b2c29272688762b"},"kernelspec":{"display_name":"Python 3.9.7 64-bit ('tf-ml': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ENFSh4IaGkcB"},"source":["In this assignment, you will experiment with different model components and architectures to design a classifier on CIFAR10 dataset."]},{"cell_type":"markdown","metadata":{"id":"_uMikSFlmS-l"},"source":["# Write Up -- General questions\n","Due to time limitations, not all possible combinations where achieved. But I was able to obtain 76 possible combinations (none of this have a skip layer)\n","\n","No normalization means that no layer was being normalized. Full normalization means that there is a normalization layer after the 1st, 3rd conv layers and the first dense layer.\n","\n","\n","\n","| Optimizer | Activation | Normalization      | Learning Schedule | Training Time | Testint Time | Acurracy | Epochs Completed | Time Per Epoch |\n","| --------- | ---------- | ------------------ | ----------------- | ------------- | ------------ | -------- | ---------------- | -------------- |\n","| Adam      | elu        | No Normalization   | Cosine Decay      | 263.63        | 0.36         | 41.9%    | 15               | 17.58          |\n","| Adam      | elu        | No Normalization   | Exponential Decay | 284.71        | 0.24         | 41.3%    | 15               | 18.98          |\n","| Adam      | tanh       | No Normalization   | Exponential Decay | 244.00        | 0.18         | 41.2%    | 15               | 16.27          |\n","| Adam      | lrelu      | No Normalization   | Exponential Decay | 262.91        | 0.37         | 40.3%    | 15               | 17.53          |\n","| Adam      | swish      | No Normalization   | Exponential Decay | 236.11        | 0.18         | 38.7%    | 15               | 15.74          |\n","| Adam      | swish      | No Normalization   | fixed             | 276.53        | 0.18         | 38.0%    | 15               | 18.44          |\n","| Adam      | relu       | No Normalization   | Exponential Decay | 226.45        | 0.17         | 37.3%    | 15               | 15.10          |\n","| Adam      | lrelu      | No Normalization   | Cosine Decay      | 268.75        | 0.36         | 36.6%    | 15               | 17.92          |\n","| Adam      | elu        | Full Normalization | Exponential Decay | 297.63        | 0.25         | 36.6%    | 15               | 19.84          |\n","| SGD       | tanh       | Full Normalization | fixed             | 262.09        | 0.18         | 30.8%    | 15               | 17.47          |\n","| SGD       | lrelu      | Full Normalization | fixed             | 269.99        | 0.36         | 29.6%    | 15               | 18.00          |\n","| Adam      | relu       | Full Normalization | Exponential Decay | 194.67        | 0.17         | 28.7%    | 11               | 17.70          |\n","| SGD       | elu        | Full Normalization | fixed             | 269.24        | 0.37         | 26.9%    | 15               | 17.95          |\n","| Adam      | lrelu      | Full Normalization | Exponential Decay | 198.09        | 0.36         | 26.3%    | 11               | 18.01          |\n","| SGD       | elu        | Full Normalization | Exponential Decay | 275.69        | 0.36         | 23.6%    | 15               | 18.38          |\n","| SGD       | elu        | No Normalization   | fixed             | 263.30        | 0.21         | 23.5%    | 15               | 17.55          |\n","| SGD       | elu        | No Normalization   | ReduceOnPlateau   | 274.00        | 0.36         | 23.2%    | 15               | 18.27          |\n","| SGD       | tanh       | No Normalization   | ReduceOnPlateau   | 243.13        | 0.18         | 22.6%    | 15               | 16.21          |\n","| SGD       | tanh       | No Normalization   | fixed             | 268.13        | 0.18         | 22.4%    | 15               | 17.88          |\n","| SGD       | tanh       | Full Normalization | Exponential Decay | 268.64        | 0.18         | 21.9%    | 15               | 17.91          |\n","| Adam      | tanh       | No Normalization   | fixed             | 202.07        | 0.18         | 19.8%    | 11               | 18.37          |\n","| SGD       | swish      | Full Normalization | fixed             | 95.35         | 0.17         | 19.8%    | 5                | 19.07          |\n","| SGD       | relu       | Full Normalization | fixed             | 179.13        | 0.17         | 19.6%    | 11               | 16.28          |\n","| Adam      | swish      | Full Normalization | Exponential Decay | 71.43         | 0.19         | 16.6%    | 5                | 14.29          |\n","| Adam      | tanh       | No Normalization   | ReduceOnPlateau   | 144.66        | 0.17         | 15.7%    | 11               | 13.15          |\n","| Adam      | tanh       | Full Normalization | Exponential Decay | 108.25        | 0.19         | 14.7%    | 6                | 18.04          |\n","| SGD       | lrelu      | Full Normalization | Exponential Decay | 51.77         | 0.23         | 13.2%    | 3                | 17.26          |\n","| SGD       | relu       | Full Normalization | Cosine Decay      | 45.94         | 0.16         | 13.2%    | 3                | 15.31          |\n","| Adam      | lrelu      | No Normalization   | ReduceOnPlateau   | 49.27         | 0.21         | 13.0%    | 3                | 16.42          |\n","| SGD       | lrelu      | No Normalization   | ReduceOnPlateau   | 50.81         | 0.36         | 13.0%    | 3                | 16.94          |\n","| SGD       | lrelu      | No Normalization   | fixed             | 56.68         | 0.36         | 12.7%    | 3                | 18.89          |\n","| SGD       | tanh       | Full Normalization | Cosine Decay      | 53.81         | 0.19         | 12.6%    | 3                | 17.94          |\n","| Adam      | tanh       | Full Normalization | fixed             | 80.06         | 0.19         | 12.4%    | 5                | 16.01          |\n","| Adam      | relu       | Full Normalization | fixed             | 54.58         | 0.18         | 12.3%    | 3                | 18.19          |\n","| Adam      | elu        | Full Normalization | fixed             | 81.63         | 0.24         | 12.3%    | 5                | 16.33          |\n","| SGD       | relu       | No Normalization   | ReduceOnPlateau   | 45.58         | 0.17         | 11.9%    | 3                | 15.19          |\n","| SGD       | swish      | No Normalization   | ReduceOnPlateau   | 45.88         | 0.17         | 11.7%    | 3                | 15.29          |\n","| SGD       | relu       | No Normalization   | fixed             | 46.16         | 0.19         | 11.6%    | 3                | 15.39          |\n","| SGD       | lrelu      | No Normalization   | Exponential Decay | 50.53         | 0.20         | 11.6%    | 3                | 16.84          |\n","| SGD       | relu       | No Normalization   | Exponential Decay | 45.58         | 0.17         | 11.5%    | 3                | 15.19          |\n","| SGD       | lrelu      | No Normalization   | Cosine Decay      | 51.39         | 0.24         | 11.5%    | 3                | 17.13          |\n","| SGD       | swish      | No Normalization   | fixed             | 46.22         | 0.17         | 11.4%    | 3                | 15.41          |\n","| SGD       | elu        | No Normalization   | Exponential Decay | 44.92         | 0.36         | 11.3%    | 3                | 14.97          |\n","| Adam      | elu        | No Normalization   | ReduceOnPlateau   | 49.80         | 0.23         | 11.2%    | 3                | 16.60          |\n","| SGD       | elu        | No Normalization   | Cosine Decay      | 50.36         | 0.36         | 11.2%    | 3                | 16.79          |\n","| SGD       | tanh       | No Normalization   | Exponential Decay | 45.35         | 0.18         | 11.0%    | 3                | 15.12          |\n","| Adam      | relu       | No Normalization   | Cosine Decay      | 45.40         | 0.17         | 10.9%    | 3                | 15.13          |\n","| SGD       | relu       | No Normalization   | Cosine Decay      | 53.57         | 0.16         | 10.9%    | 3                | 17.86          |\n","| Adam      | tanh       | No Normalization   | Cosine Decay      | 53.83         | 0.19         | 10.8%    | 3                | 17.94          |\n","| SGD       | tanh       | No Normalization   | Cosine Decay      | 45.48         | 0.19         | 10.8%    | 3                | 15.16          |\n","| SGD       | relu       | Full Normalization | Exponential Decay | 46.21         | 0.17         | 10.8%    | 3                | 15.40          |\n","| Adam      | lrelu      | Full Normalization | fixed             | 127.65        | 0.36         | 10.7%    | 7                | 18.24          |\n","| Adam      | swish      | Full Normalization | fixed             | 46.49         | 0.18         | 10.5%    | 3                | 15.50          |\n","| SGD       | swish      | Full Normalization | Exponential Decay | 54.43         | 0.20         | 10.5%    | 3                | 18.14          |\n","| SGD       | swish      | No Normalization   | Exponential Decay | 38.16         | 0.18         | 10.5%    | 3                | 12.72          |\n","| Adam      | elu        | No Normalization   | fixed             | 56.30         | 0.35         | 10.2%    | 3                | 18.77          |\n","| Adam      | swish      | No Normalization   | Cosine Decay      | 45.67         | 0.17         | 10.2%    | 3                | 15.22          |\n","| SGD       | swish      | No Normalization   | Cosine Decay      | 46.07         | 0.19         | 10.2%    | 3                | 15.36          |\n","| Adam      | sigmoid    | Full Normalization | fixed             | 57.52         | 0.37         | 10.0%    | 3                | 19.17          |\n","| Adam      | swish      | No Normalization   | ReduceOnPlateau   | 54.16         | 10.27        | 10.0%    | 3                | 18.05          |\n","| Adam      | relu       | No Normalization   | ReduceOnPlateau   | 54.03         | 0.16         | 10.0%    | 3                | 18.01          |\n","| Adam      | sigmoid    | Full Normalization | Exponential Decay | 51.62         | 0.26         | 10.0%    | 3                | 17.21          |\n","| Adam      | sigmoid    | No Normalization   | fixed             | 50.07         | 0.37         | 10.0%    | 3                | 16.69          |\n","| Adam      | sigmoid    | No Normalization   | ReduceOnPlateau   | 49.63         | 0.29         | 10.0%    | 3                | 16.54          |\n","| Adam      | sigmoid    | No Normalization   | Exponential Decay | 49.19         | 0.20         | 10.0%    | 3                | 16.40          |\n","| Adam      | sigmoid    | No Normalization   | Cosine Decay      | 44.85         | 0.36         | 10.0%    | 3                | 14.95          |\n","| Adam      | relu       | No Normalization   | fixed             | 45.68         | 0.19         | 10.0%    | 3                | 15.23          |\n","| SGD       | sigmoid    | No Normalization   | Cosine Decay      | 50.68         | 0.36         | 10.0%    | 3                | 16.89          |\n","| SGD       | sigmoid    | Full Normalization | Exponential Decay | 57.01         | 0.24         | 10.0%    | 3                | 19.00          |\n","| SGD       | sigmoid    | Full Normalization | fixed             | 53.04         | 0.37         | 10.0%    | 3                | 17.68          |\n","| SGD       | sigmoid    | Full Normalization | Cosine Decay      | 51.10         | 0.22         | 10.0%    | 3                | 17.03          |\n","| SGD       | sigmoid    | No Normalization   | fixed             | 50.16         | 0.20         | 10.0%    | 3                | 16.72          |\n","| SGD       | sigmoid    | No Normalization   | ReduceOnPlateau   | 50.03         | 0.37         | 10.0%    | 3                | 16.68          |\n","| SGD       | sigmoid    | No Normalization   | Exponential Decay | 112.21        | 0.35         | 10.0%    | 3                | 37.40          |\n","| SGD       | swish      | Full Normalization | Cosine Decay      | 46.71         | 0.19         | 10.0%    | 3                | 15.57          |\n","| Adam      | lrelu      | No Normalization   | fixed             | 45.10         | 0.36         | 8.3%     | 3                | 15.03          |"]},{"cell_type":"markdown","metadata":{"id":"oX8J9cUIrYfu"},"source":["# Write Up -- Challenge question\n","[click to edit]\n"]},{"cell_type":"markdown","metadata":{"id":"LweTw8wQnj9b"},"source":["# Tasks [choose **GPU** with **either Pytorch or Tensorflow**]"]},{"cell_type":"markdown","metadata":{"id":"wXF9Eo5jR53d"},"source":["## General Explorations\n","In assignment 1, you had the experience of running and benchmarking the same CNN model with different combinations of platforms and hardware choices. Now in assignment 2, we would like you to start with the provided base model and tweak it with different components and structures. Please provide a writeup describing your findings of the following items:\n","\n","- Effects on **trainability**: Fixed initial states, fixed total iterations, does it converge on each setting, fast or slow?\n","- Effects on **accuracy**: Fixed initial states, fixed total iterations, what's the test accuracy for each setting? \n","- Effects on **speed (samples / second)**: What's the speed for 1 training epoch? What's the speed for 1 inference(test) epoch?\n","\n","## Activation functions:\n","[Wiki](https://en.wikipedia.org/wiki/Activation_function#Sign_equivalence_to_identity_function)\n","[Pytorch](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n","[Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/activations)\n","\n","_\\* for simplicity, assume all activation functions within a network to be the same_\n","1. Sigmoid\n","2. TanH\n","3. ReLU\n","4. ELU\n","5. Leaky ReLU\n","6. Swish (SiLU)\n","\n","## Skip connections:\n","[Pytorch & Tensorflow have quite similar style nowadays](https://discuss.pytorch.org/t/how-to-write-your-own-skip-connections-in-pytorch/88618)\n","- no skip\n","- skip 1 layer, trainable parameters\n","- skip 2 layers, trainable parameters\n","\n","## Batch normalization:\n","[Pytorch](https://pytorch.org/docs/stable/nn.html#normalization-layers)\n","[Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization)\n","\n","- on vs. off\n","- when: before vs. after activation?\n","- where: uniformly apply vs. only after certain layers?\n","\n","## Optimizers:\n","[Pytorch](https://pytorch.org/docs/stable/optim.html#algorithms)\n","[Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)\n","1. SGD\n","2. Adam\n","\n","## Learning rate (scheduler):\n","[Pytorch](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)\n","[Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules)\n","- constant learning rate\n","- step decay / exponential decay\n","- ReduceOnPlateau\n","- Annealing Schedule"]},{"cell_type":"markdown","metadata":{"id":"PRfJ1wJlkcTE"},"source":["## Challenge Question: does skip connection alone provides better performance without re-training? [Optional]\n","bring your best model, freeze all its parameters, add skip connections, does it improve on test accuracy?\n","\n","How to do this:\n","- save the trained model parameters\n","- add skip connection in code of model definition [how to](https://discuss.pytorch.org/t/how-to-write-your-own-skip-connections-in-pytorch/88618)\n","- reload the parameters\n","- start inference"]},{"cell_type":"markdown","metadata":{"id":"7X9SeBUBWcSF"},"source":["# Set up storage and download dataset"]},{"cell_type":"markdown","metadata":{"id":"SlU-gEiGzSVC"},"source":["## Connect to google drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uk48pYb1GSCo","executionInfo":{"elapsed":20020,"status":"ok","timestamp":1634140846041,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"},"user_tz":300},"outputId":"5363ea66-80b8-466c-89ed-60b476bf74ae"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1dhlOA4PGvZ5","executionInfo":{"elapsed":569,"status":"ok","timestamp":1634140848364,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"},"user_tz":300},"outputId":"f1e60220-81a0-4945-bc31-8f1cc9b90ba2"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Oct 13 16:00:47 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"mMaPX_HSSnOA"},"source":["## What do we use for dataset?\n","We will be using CIFAR10 and some of its derivatives for this assignment. Following descripions are from tensorflow dataset website.\n","\n","- The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. This serves as our training set\\\n","Homepage: https://www.cs.toronto.edu/~kriz/cifar.html\n","\n","- The CIFAR-10.1 dataset is a new test set for CIFAR-10. CIFAR-10.1 contains roughly 2,000 new test images that were sampled after multiple years of research on the original CIFAR-10 dataset. The data collection for CIFAR-10.1 was designed to minimize distribution shift relative to the original dataset. We describe the creation of CIFAR-10.1 in the paper \"Do CIFAR-10 Classifiers Generalize to CIFAR-10?\". The images in CIFAR-10.1 are a subset of the TinyImages dataset. There are currently two versions of the CIFAR-10.1 dataset: v4 and v6. **We use v6 for this assignment.** \\\n","Homepage: https://github.com/modestyachts/CIFAR-10.1\n","\n","To prepare for the future assignments & projects, we will load datasets by manual efforts to mimic the data loading process in most of the real world DL experiments. For storage, we will use Google Drive.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0FlFQx3bjOE","executionInfo":{"elapsed":3706,"status":"ok","timestamp":1634085943406,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"},"user_tz":300},"outputId":"40f4cbcb-1e7f-442b-9ed9-17add6373fbe"},"source":["# Download CIFAR10 & CIFAR10.1 v6\n","!mkdir -p \"/content/drive/MyDrive/Deep Learning System/assignment-2/data/\"\n","%cd \"/content/drive/MyDrive/Deep Learning System/assignment-2/data/\"\n","!wget \"https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\" -O \"cifar-10-binary.tar.gz\"\n","!wget \"https://github.com/modestyachts/CIFAR-10.1/raw/master/datasets/cifar10.1_v6_data.npy\" -O \"cifar10.1_v6_data.npy\"\n","!wget \"https://github.com/modestyachts/CIFAR-10.1/raw/master/datasets/cifar10.1_v6_labels.npy\" -O \"cifar10.1_v6_labels.npy\""],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Deep Learning System/assignment-2/data\n","--2021-10-13 00:45:39--  https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\n","Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n","Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 170052171 (162M) [application/x-gzip]\n","Saving to: ‘cifar-10-binary.tar.gz’\n","\n","cifar-10-binary.tar 100%[===================>] 162.17M  73.1MB/s    in 2.2s    \n","\n","2021-10-13 00:45:42 (73.1 MB/s) - ‘cifar-10-binary.tar.gz’ saved [170052171/170052171]\n","\n","--2021-10-13 00:45:42--  https://github.com/modestyachts/CIFAR-10.1/raw/master/datasets/cifar10.1_v6_data.npy\n","Resolving github.com (github.com)... 140.82.112.4\n","Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/modestyachts/CIFAR-10.1/master/datasets/cifar10.1_v6_data.npy [following]\n","--2021-10-13 00:45:42--  https://raw.githubusercontent.com/modestyachts/CIFAR-10.1/master/datasets/cifar10.1_v6_data.npy\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6144128 (5.9M) [application/octet-stream]\n","Saving to: ‘cifar10.1_v6_data.npy’\n","\n","cifar10.1_v6_data.n 100%[===================>]   5.86M  --.-KB/s    in 0.08s   \n","\n","2021-10-13 00:45:42 (75.6 MB/s) - ‘cifar10.1_v6_data.npy’ saved [6144128/6144128]\n","\n","--2021-10-13 00:45:42--  https://github.com/modestyachts/CIFAR-10.1/raw/master/datasets/cifar10.1_v6_labels.npy\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/modestyachts/CIFAR-10.1/master/datasets/cifar10.1_v6_labels.npy [following]\n","--2021-10-13 00:45:43--  https://raw.githubusercontent.com/modestyachts/CIFAR-10.1/master/datasets/cifar10.1_v6_labels.npy\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 8128 (7.9K) [application/octet-stream]\n","Saving to: ‘cifar10.1_v6_labels.npy’\n","\n","cifar10.1_v6_labels 100%[===================>]   7.94K  --.-KB/s    in 0s      \n","\n","2021-10-13 00:45:43 (83.9 MB/s) - ‘cifar10.1_v6_labels.npy’ saved [8128/8128]\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JYYGFG6IguVb","executionInfo":{"elapsed":2158,"status":"ok","timestamp":1634085945562,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"},"user_tz":300},"outputId":"00cc68f3-0860-4fd3-b8b7-e54f43a00065"},"source":["# decompress the tar.gz. It will create a folder `cifar-10-batches-bin/` under `/content/drive/MyDrive/Deep Learning System/assignment-2/data/`\n","!tar -xvzf \"/content/drive/MyDrive/Deep Learning System/assignment-2/data/cifar-10-binary.tar.gz\""],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["cifar-10-batches-bin/\n","cifar-10-batches-bin/data_batch_1.bin\n","cifar-10-batches-bin/batches.meta.txt\n","cifar-10-batches-bin/data_batch_3.bin\n","cifar-10-batches-bin/data_batch_4.bin\n","cifar-10-batches-bin/test_batch.bin\n","cifar-10-batches-bin/readme.html\n","cifar-10-batches-bin/data_batch_5.bin\n","cifar-10-batches-bin/data_batch_2.bin\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZnxRVQsfmphb"},"source":["# Tensorflow Script"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T__xbLTtz5DN","executionInfo":{"elapsed":7316,"status":"ok","timestamp":1634140869034,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"},"user_tz":300},"outputId":"3adf9915-54df-46d7-b91d-18c7b9dae697"},"source":["# tensorflow packages setup\n","!pip3 install --no-cache-dir tensorflow==2.6.0 tensorflow-datasets==4.4.0 tensorflow_addons==0.14"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.6.0 (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for tensorflow==2.6.0\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"h6Nj4QkdWRi_"},"source":["## Environment setup"]},{"cell_type":"code","metadata":{"id":"JkZeL8pNWRjF"},"source":["import os\n","import random\n","import numpy as np\n","import tensorflow as tf\n","\n","# common variables\n","BATCH_SIZE = 8192\n","EPOCHS = 15\n","SEED = 3456\n","\n","# fix random seed\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_oN85I19XDy0"},"source":["## Parse and build customized dataset\n","\n","Data format - Binary version: https://www.cs.toronto.edu/~kriz/cifar.html\n","\n","The binary version contains the files data_batch_1.bin, data_batch_2.bin, ..., data_batch_5.bin, as well as test_batch.bin. Each of these files is formatted as follows:\n","```\n","<1 x label><3072 x pixel>\n","...\n","<1 x label><3072 x pixel>\n","```\n","In other words, the first byte is the label of the first image, which is a number in the range 0-9. The next 3072 bytes are the values of the pixels of the image. The first 1024 bytes are the red channel values, the next 1024 the green, and the final 1024 the blue. The values are stored in row-major order, so the first 32 bytes are the red channel values of the first row of the image.\n","\n","Each file contains 10000 such 3073-byte \"rows\" of images, although there is nothing delimiting the rows. Therefore each file should be exactly 30730000 bytes long.\n","\n","There is another file, called batches.meta.txt. This is an ASCII file that maps numeric labels in the range 0-9 to meaningful class names. It is merely a list of the 10 class names, one per row. The class name on row i corresponds to numeric label i."]},{"cell_type":"markdown","metadata":{"id":"FZPVg1Wws35y"},"source":["### Tensorflow Dataset Object <a name=\"tf-dataset\"></a>\n","\n","https://www.tensorflow.org/datasets/add_dataset\n","\n","TF2.0 Dataset structure looks very similar to its Pytorch counterpart."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xhx_yhfo8w22","executionInfo":{"status":"ok","timestamp":1634177866558,"user_tz":300,"elapsed":712,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5W-d5yrTmNK52k4FxEIWC7RkPt_KB9gdJgq6YUA=s64","userId":"08509759692231921764"}},"outputId":"56f76065-f32e-4b0f-bfbf-a945b35c7ac1"},"source":["!mkdir -p \"/content/drive/MyDrive/Deep Learning System/assignment-2/data/\"\n","%cd \"/content/drive/MyDrive/Deep Learning System/assignment-2/data/\"\n","\n","![ ! -d \"CIFAR35200\" ] && tfds new CIFAR35200"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Deep Learning System/assignment-2/data\n"]}]},{"cell_type":"markdown","metadata":{"id":"YQ2tbpDGSQHP"},"source":["This will create a folder named \"CIFAR35200\" in `/content/drive/MyDrive/Deep Learning System/assignment-2/data/`. Edit the `CIFAR35200.py` template to define the dataset behavior. For your convenience, here is my `CIFAR35200.py`: https://drive.google.com/file/d/16cIRqrYt6DBBTPru2Dt6ghDpXq4ACZMa/view?usp=sharing \\\n","Please be aware that I changed the file extension to `*.txt` to make it possible for `wget` to work properly. You should restore it to `*.py` if you replicate the changes manually.\n","\n","Let's build this dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ed8s4DM4QVxY","executionInfo":{"status":"ok","timestamp":1634177934219,"user_tz":300,"elapsed":66992,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5W-d5yrTmNK52k4FxEIWC7RkPt_KB9gdJgq6YUA=s64","userId":"08509759692231921764"}},"outputId":"64eb650c-bcab-443a-8c73-7ef7b02cc1f4"},"source":["![ -d \"/root/tensorflow_datasets/cifar35200/\" ] && rm /root/tensorflow_datasets/cifar35200/ -r\n","\n","# build should perform in the \"CIFAR35200\" template folder\n","%cd \"/content/drive/MyDrive/Deep Learning System/assignment-2/data/CIFAR35200\"\n","\n","# here we directly download the provided CIFAR35200.py. Take some time to study it\n","# https://bcrf.biochem.wisc.edu/2021/02/05/download-google-drive-files-using-wget/\n","!wget --no-check-certificate \"https://docs.google.com/uc?export=download&id=16cIRqrYt6DBBTPru2Dt6ghDpXq4ACZMa\" -O CIFAR35200.py\n","\n","# --manual_dir should point to the directory where your extacted dataset locates\n","!tfds build --manual_dir=\"/content/drive/MyDrive/Deep Learning System/assignment-2/data\"\n","\n","# you will see a test run through the dataset, log ended with dataset info"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Deep Learning System/assignment-2/data/CIFAR35200\n","--2021-10-14 02:17:47--  https://docs.google.com/uc?export=download&id=16cIRqrYt6DBBTPru2Dt6ghDpXq4ACZMa\n","Resolving docs.google.com (docs.google.com)... 74.125.135.139, 74.125.135.113, 74.125.135.138, ...\n","Connecting to docs.google.com (docs.google.com)|74.125.135.139|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-0k-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/soq5u3ade5b88klvl0dq33o63p9uqlfi/1634177850000/08765295497597902326/*/16cIRqrYt6DBBTPru2Dt6ghDpXq4ACZMa?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-10-14 02:17:48--  https://doc-0k-a8-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/soq5u3ade5b88klvl0dq33o63p9uqlfi/1634177850000/08765295497597902326/*/16cIRqrYt6DBBTPru2Dt6ghDpXq4ACZMa?e=download\n","Resolving doc-0k-a8-docs.googleusercontent.com (doc-0k-a8-docs.googleusercontent.com)... 74.125.135.132, 2607:f8b0:400e:c01::84\n","Connecting to doc-0k-a8-docs.googleusercontent.com (doc-0k-a8-docs.googleusercontent.com)|74.125.135.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4797 (4.7K) [text/plain]\n","Saving to: ‘CIFAR35200.py’\n","\n","CIFAR35200.py       100%[===================>]   4.68K  --.-KB/s    in 0s      \n","\n","2021-10-14 02:17:48 (14.4 MB/s) - ‘CIFAR35200.py’ saved [4797/4797]\n","\n","2021-10-14 02:17:50.887406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-14 02:17:50.896578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-14 02:17:50.897466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","INFO[build.py]: Loading dataset  from path: /content/drive/My Drive/Deep Learning System/assignment-2/data/CIFAR35200/CIFAR35200.py\n","2021-10-14 02:17:51.153362: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-14 02:17:51.229232: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","INFO[build.py]: download_and_prepare for dataset cifar35200/1.0.0...\n","INFO[dataset_builder.py]: Generating dataset cifar35200 (/root/tensorflow_datasets/cifar35200/1.0.0)\n","\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/cifar35200/1.0.0...\u001b[0m\n","2021-10-14 02:17:51.389931: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2021-10-14 02:17:51.466677: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","Generating splits...:   0% 0/3 [00:00<?, ? splits/s]\n","Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A2021-10-14 02:17:51.654922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-14 02:17:51.655927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-14 02:17:51.656854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-14 02:17:52.244546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-14 02:17:52.245488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-14 02:17:52.246271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-10-14 02:17:52.246987: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-10-14 02:17:52.247065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14756 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","\n","Generating train examples...: 1 examples [00:00,  1.45 examples/s]\u001b[A\n","Generating train examples...: 112 examples [00:00, 191.74 examples/s]\u001b[A\n","Generating train examples...: 216 examples [00:00, 358.38 examples/s]\u001b[A\n","Generating train examples...: 318 examples [00:00, 503.41 examples/s]\u001b[A\n","Generating train examples...: 421 examples [00:01, 628.83 examples/s]\u001b[A\n","Generating train examples...: 516 examples [00:01, 708.35 examples/s]\u001b[A\n","Generating train examples...: 624 examples [00:01, 805.95 examples/s]\u001b[A\n","Generating train examples...: 730 examples [00:01, 874.91 examples/s]\u001b[A\n","Generating train examples...: 834 examples [00:01, 919.82 examples/s]\u001b[A\n","Generating train examples...: 942 examples [00:01, 965.06 examples/s]\u001b[A\n","Generating train examples...: 1046 examples [00:01, 968.43 examples/s]\u001b[A\n","Generating train examples...: 1148 examples [00:01, 981.02 examples/s]\u001b[A\n","Generating train examples...: 1255 examples [00:01, 1004.66 examples/s]\u001b[A\n","Generating train examples...: 1358 examples [00:02, 999.65 examples/s] \u001b[A\n","Generating train examples...: 1460 examples [00:02, 1000.74 examples/s]\u001b[A\n","Generating train examples...: 1567 examples [00:02, 1021.07 examples/s]\u001b[A\n","Generating train examples...: 1673 examples [00:02, 1030.36 examples/s]\u001b[A\n","Generating train examples...: 1781 examples [00:02, 1043.95 examples/s]\u001b[A\n","Generating train examples...: 1888 examples [00:02, 1048.59 examples/s]\u001b[A\n","Generating train examples...: 1994 examples [00:02, 1047.84 examples/s]\u001b[A\n","Generating train examples...: 2100 examples [00:02, 1026.66 examples/s]\u001b[A\n","Generating train examples...: 2204 examples [00:02, 1030.35 examples/s]\u001b[A\n","Generating train examples...: 2309 examples [00:02, 1034.18 examples/s]\u001b[A\n","Generating train examples...: 2416 examples [00:03, 1042.00 examples/s]\u001b[A\n","Generating train examples...: 2521 examples [00:03, 1021.79 examples/s]\u001b[A\n","Generating train examples...: 2627 examples [00:03, 1031.39 examples/s]\u001b[A\n","Generating train examples...: 2731 examples [00:03, 1030.19 examples/s]\u001b[A\n","Generating train examples...: 2839 examples [00:03, 1042.43 examples/s]\u001b[A\n","Generating train examples...: 2948 examples [00:03, 1053.93 examples/s]\u001b[A\n","Generating train examples...: 3055 examples [00:03, 1056.58 examples/s]\u001b[A\n","Generating train examples...: 3161 examples [00:03, 1046.29 examples/s]\u001b[A\n","Generating train examples...: 3267 examples [00:03, 1049.79 examples/s]\u001b[A\n","Generating train examples...: 3373 examples [00:03, 1039.07 examples/s]\u001b[A\n","Generating train examples...: 3479 examples [00:04, 1044.94 examples/s]\u001b[A\n","Generating train examples...: 3584 examples [00:04, 1033.92 examples/s]\u001b[A\n","Generating train examples...: 3688 examples [00:04, 1022.43 examples/s]\u001b[A\n","Generating train examples...: 3796 examples [00:04, 1037.41 examples/s]\u001b[A\n","Generating train examples...: 3900 examples [00:04, 1029.07 examples/s]\u001b[A\n","Generating train examples...: 4003 examples [00:04, 1018.46 examples/s]\u001b[A\n","Generating train examples...: 4105 examples [00:04, 1003.83 examples/s]\u001b[A\n","Generating train examples...: 4206 examples [00:04, 1001.81 examples/s]\u001b[A\n","Generating train examples...: 4312 examples [00:04, 1018.91 examples/s]\u001b[A\n","Generating train examples...: 4418 examples [00:04, 1030.30 examples/s]\u001b[A\n","Generating train examples...: 4522 examples [00:05, 1007.21 examples/s]\u001b[A\n","Generating train examples...: 4624 examples [00:05, 1008.67 examples/s]\u001b[A\n","Generating train examples...: 4729 examples [00:05, 1018.83 examples/s]\u001b[A\n","Generating train examples...: 4836 examples [00:05, 1031.84 examples/s]\u001b[A\n","Generating train examples...: 4940 examples [00:05, 966.11 examples/s] \u001b[A\n","Generating train examples...: 5047 examples [00:05, 994.43 examples/s]\u001b[A\n","Generating train examples...: 5151 examples [00:05, 1007.09 examples/s]\u001b[A\n","Generating train examples...: 5253 examples [00:05, 1000.28 examples/s]\u001b[A\n","Generating train examples...: 5354 examples [00:05, 985.74 examples/s] \u001b[A\n","Generating train examples...: 5455 examples [00:06, 991.01 examples/s]\u001b[A\n","Generating train examples...: 5557 examples [00:06, 998.25 examples/s]\u001b[A\n","Generating train examples...: 5657 examples [00:06, 992.65 examples/s]\u001b[A\n","Generating train examples...: 5757 examples [00:06, 992.07 examples/s]\u001b[A\n","Generating train examples...: 5864 examples [00:06, 1014.87 examples/s]\u001b[A\n","Generating train examples...: 5966 examples [00:06, 995.90 examples/s] \u001b[A\n","Generating train examples...: 6069 examples [00:06, 1003.95 examples/s]\u001b[A\n","Generating train examples...: 6171 examples [00:06, 1006.99 examples/s]\u001b[A\n","Generating train examples...: 6275 examples [00:06, 1015.29 examples/s]\u001b[A\n","Generating train examples...: 6382 examples [00:06, 1030.45 examples/s]\u001b[A\n","Generating train examples...: 6491 examples [00:07, 1047.65 examples/s]\u001b[A\n","Generating train examples...: 6596 examples [00:07, 1031.85 examples/s]\u001b[A\n","Generating train examples...: 6700 examples [00:07, 1005.56 examples/s]\u001b[A\n","Generating train examples...: 6803 examples [00:07, 1012.52 examples/s]\u001b[A\n","Generating train examples...: 6909 examples [00:07, 1025.79 examples/s]\u001b[A\n","Generating train examples...: 7012 examples [00:07, 1025.80 examples/s]\u001b[A\n","Generating train examples...: 7115 examples [00:07, 1007.83 examples/s]\u001b[A\n","Generating train examples...: 7216 examples [00:07, 986.57 examples/s] \u001b[A\n","Generating train examples...: 7315 examples [00:07, 983.73 examples/s]\u001b[A\n","Generating train examples...: 7414 examples [00:07, 972.74 examples/s]\u001b[A\n","Generating train examples...: 7512 examples [00:08, 956.35 examples/s]\u001b[A\n","Generating train examples...: 7616 examples [00:08, 978.00 examples/s]\u001b[A\n","Generating train examples...: 7718 examples [00:08, 989.55 examples/s]\u001b[A\n","Generating train examples...: 7822 examples [00:08, 1002.63 examples/s]\u001b[A\n","Generating train examples...: 7923 examples [00:08, 991.47 examples/s] \u001b[A\n","Generating train examples...: 8025 examples [00:08, 999.32 examples/s]\u001b[A\n","Generating train examples...: 8126 examples [00:08, 991.09 examples/s]\u001b[A\n","Generating train examples...: 8226 examples [00:08, 963.63 examples/s]\u001b[A\n","Generating train examples...: 8326 examples [00:08, 972.72 examples/s]\u001b[A\n","Generating train examples...: 8424 examples [00:08, 972.62 examples/s]\u001b[A\n","Generating train examples...: 8522 examples [00:09, 972.63 examples/s]\u001b[A\n","Generating train examples...: 8627 examples [00:09, 992.90 examples/s]\u001b[A\n","Generating train examples...: 8727 examples [00:09, 991.16 examples/s]\u001b[A\n","Generating train examples...: 8827 examples [00:09, 992.46 examples/s]\u001b[A\n","Generating train examples...: 8928 examples [00:09, 996.70 examples/s]\u001b[A\n","Generating train examples...: 9028 examples [00:09, 991.58 examples/s]\u001b[A\n","Generating train examples...: 9128 examples [00:09, 988.03 examples/s]\u001b[A\n","Generating train examples...: 9227 examples [00:09, 975.39 examples/s]\u001b[A\n","Generating train examples...: 9330 examples [00:09, 989.48 examples/s]\u001b[A\n","Generating train examples...: 9430 examples [00:09, 992.36 examples/s]\u001b[A\n","Generating train examples...: 9530 examples [00:10, 990.63 examples/s]\u001b[A\n","Generating train examples...: 9630 examples [00:10, 986.48 examples/s]\u001b[A\n","Generating train examples...: 9738 examples [00:10, 1011.50 examples/s]\u001b[A\n","Generating train examples...: 9845 examples [00:10, 1028.04 examples/s]\u001b[A\n","Generating train examples...: 9948 examples [00:10, 1013.61 examples/s]\u001b[A\n","Generating train examples...: 10050 examples [00:10, 776.86 examples/s]\u001b[A\n","Generating train examples...: 10148 examples [00:10, 824.89 examples/s]\u001b[A\n","Generating train examples...: 10255 examples [00:10, 887.70 examples/s]\u001b[A\n","Generating train examples...: 10360 examples [00:11, 922.99 examples/s]\u001b[A\n","Generating train examples...: 10464 examples [00:11, 954.35 examples/s]\u001b[A\n","Generating train examples...: 10566 examples [00:11, 970.94 examples/s]\u001b[A\n","Generating train examples...: 10668 examples [00:11, 984.08 examples/s]\u001b[A\n","Generating train examples...: 10774 examples [00:11, 1005.61 examples/s]\u001b[A\n","Generating train examples...: 10877 examples [00:11, 1010.64 examples/s]\u001b[A\n","Generating train examples...: 10979 examples [00:11, 1001.95 examples/s]\u001b[A\n","Generating train examples...: 11080 examples [00:11, 996.55 examples/s] \u001b[A\n","Generating train examples...: 11181 examples [00:11, 979.66 examples/s]\u001b[A\n","Generating train examples...: 11285 examples [00:11, 996.37 examples/s]\u001b[A\n","Generating train examples...: 11386 examples [00:12, 998.77 examples/s]\u001b[A\n","Generating train examples...: 11491 examples [00:12, 1011.60 examples/s]\u001b[A\n","Generating train examples...: 11594 examples [00:12, 1016.88 examples/s]\u001b[A\n","Generating train examples...: 11696 examples [00:12, 1016.34 examples/s]\u001b[A\n","Generating train examples...: 11801 examples [00:12, 1024.88 examples/s]\u001b[A\n","Generating train examples...: 11907 examples [00:12, 1033.37 examples/s]\u001b[A\n","Generating train examples...: 12011 examples [00:12, 1028.49 examples/s]\u001b[A\n","Generating train examples...: 12114 examples [00:12, 1025.71 examples/s]\u001b[A\n","Generating train examples...: 12217 examples [00:12, 999.76 examples/s] \u001b[A\n","Generating train examples...: 12318 examples [00:12, 1001.89 examples/s]\u001b[A\n","Generating train examples...: 12419 examples [00:13, 999.79 examples/s] \u001b[A\n","Generating train examples...: 12521 examples [00:13, 1003.82 examples/s]\u001b[A\n","Generating train examples...: 12622 examples [00:13, 995.19 examples/s] \u001b[A\n","Generating train examples...: 12725 examples [00:13, 1003.40 examples/s]\u001b[A\n","Generating train examples...: 12832 examples [00:13, 1019.91 examples/s]\u001b[A\n","Generating train examples...: 12935 examples [00:13, 1014.99 examples/s]\u001b[A\n","Generating train examples...: 13038 examples [00:13, 1018.98 examples/s]\u001b[A\n","Generating train examples...: 13140 examples [00:13, 1018.19 examples/s]\u001b[A\n","Generating train examples...: 13242 examples [00:13, 994.79 examples/s] \u001b[A\n","Generating train examples...: 13351 examples [00:13, 1019.85 examples/s]\u001b[A\n","Generating train examples...: 13459 examples [00:14, 1035.97 examples/s]\u001b[A\n","Generating train examples...: 13567 examples [00:14, 1045.53 examples/s]\u001b[A\n","Generating train examples...: 13673 examples [00:14, 1049.48 examples/s]\u001b[A\n","Generating train examples...: 13779 examples [00:14, 1050.79 examples/s]\u001b[A\n","Generating train examples...: 13885 examples [00:14, 998.31 examples/s] \u001b[A\n","Generating train examples...: 13992 examples [00:14, 1016.93 examples/s]\u001b[A\n","Generating train examples...: 14097 examples [00:14, 1025.08 examples/s]\u001b[A\n","Generating train examples...: 14203 examples [00:14, 1034.06 examples/s]\u001b[A\n","Generating train examples...: 14307 examples [00:14, 1031.79 examples/s]\u001b[A\n","Generating train examples...: 14411 examples [00:14, 1027.35 examples/s]\u001b[A\n","Generating train examples...: 14518 examples [00:15, 1038.52 examples/s]\u001b[A\n","Generating train examples...: 14624 examples [00:15, 1043.24 examples/s]\u001b[A\n","Generating train examples...: 14730 examples [00:15, 1048.15 examples/s]\u001b[A\n","Generating train examples...: 14835 examples [00:15, 1047.75 examples/s]\u001b[A\n","Generating train examples...: 14940 examples [00:15, 1036.37 examples/s]\u001b[A\n","Generating train examples...: 15044 examples [00:15, 1016.06 examples/s]\u001b[A\n","Generating train examples...: 15152 examples [00:15, 1032.45 examples/s]\u001b[A\n","Generating train examples...: 15262 examples [00:15, 1052.00 examples/s]\u001b[A\n","Generating train examples...: 15368 examples [00:15, 1041.05 examples/s]\u001b[A\n","Generating train examples...: 15478 examples [00:16, 1056.30 examples/s]\u001b[A\n","Generating train examples...: 15584 examples [00:16, 1057.17 examples/s]\u001b[A\n","Generating train examples...: 15691 examples [00:16, 1057.95 examples/s]\u001b[A\n","Generating train examples...: 15798 examples [00:16, 1059.62 examples/s]\u001b[A\n","Generating train examples...: 15904 examples [00:16, 1055.17 examples/s]\u001b[A\n","Generating train examples...: 16011 examples [00:16, 1057.16 examples/s]\u001b[A\n","Generating train examples...: 16117 examples [00:16, 1053.43 examples/s]\u001b[A\n","Generating train examples...: 16223 examples [00:16, 1052.24 examples/s]\u001b[A\n","Generating train examples...: 16329 examples [00:16, 1046.99 examples/s]\u001b[A\n","Generating train examples...: 16434 examples [00:16, 1044.24 examples/s]\u001b[A\n","Generating train examples...: 16541 examples [00:17, 1050.75 examples/s]\u001b[A\n","Generating train examples...: 16647 examples [00:17, 1044.46 examples/s]\u001b[A\n","Generating train examples...: 16755 examples [00:17, 1054.56 examples/s]\u001b[A\n","Generating train examples...: 16865 examples [00:17, 1068.01 examples/s]\u001b[A\n","Generating train examples...: 16972 examples [00:17, 1062.49 examples/s]\u001b[A\n","Generating train examples...: 17079 examples [00:17, 1061.15 examples/s]\u001b[A\n","Generating train examples...: 17191 examples [00:17, 1077.87 examples/s]\u001b[A\n","Generating train examples...: 17299 examples [00:17, 1062.94 examples/s]\u001b[A\n","Generating train examples...: 17406 examples [00:17, 1055.44 examples/s]\u001b[A\n","Generating train examples...: 17513 examples [00:17, 1057.36 examples/s]\u001b[A\n","Generating train examples...: 17619 examples [00:18, 1051.32 examples/s]\u001b[A\n","Generating train examples...: 17725 examples [00:18, 1040.88 examples/s]\u001b[A\n","Generating train examples...: 17835 examples [00:18, 1056.47 examples/s]\u001b[A\n","Generating train examples...: 17941 examples [00:18, 1055.34 examples/s]\u001b[A\n","Generating train examples...: 18050 examples [00:18, 1064.33 examples/s]\u001b[A\n","Generating train examples...: 18157 examples [00:18, 1064.46 examples/s]\u001b[A\n","Generating train examples...: 18266 examples [00:18, 1069.56 examples/s]\u001b[A\n","Generating train examples...: 18373 examples [00:18, 1062.98 examples/s]\u001b[A\n","Generating train examples...: 18485 examples [00:18, 1078.83 examples/s]\u001b[A\n","Generating train examples...: 18593 examples [00:18, 1062.33 examples/s]\u001b[A\n","Generating train examples...: 18704 examples [00:19, 1075.72 examples/s]\u001b[A\n","Generating train examples...: 18812 examples [00:19, 1051.50 examples/s]\u001b[A\n","Generating train examples...: 18918 examples [00:19, 1045.76 examples/s]\u001b[A\n","Generating train examples...: 19030 examples [00:19, 1064.51 examples/s]\u001b[A\n","Generating train examples...: 19137 examples [00:19, 1060.58 examples/s]\u001b[A\n","Generating train examples...: 19251 examples [00:19, 1083.78 examples/s]\u001b[A\n","Generating train examples...: 19360 examples [00:19, 1053.39 examples/s]\u001b[A\n","Generating train examples...: 19466 examples [00:19, 1018.49 examples/s]\u001b[A\n","Generating train examples...: 19572 examples [00:19, 1010.42 examples/s]\u001b[A\n","Generating train examples...: 19679 examples [00:19, 1026.88 examples/s]\u001b[A\n","Generating train examples...: 19787 examples [00:20, 1040.84 examples/s]\u001b[A\n","Generating train examples...: 19892 examples [00:20, 1015.02 examples/s]\u001b[A\n","Generating train examples...: 19996 examples [00:20, 1021.36 examples/s]\u001b[A\n","Generating train examples...: 20099 examples [00:20, 815.41 examples/s] \u001b[A\n","Generating train examples...: 20212 examples [00:20, 893.14 examples/s]\u001b[A\n","Generating train examples...: 20320 examples [00:20, 929.71 examples/s]\u001b[A\n","Generating train examples...: 20426 examples [00:20, 957.81 examples/s]\u001b[A\n","Generating train examples...: 20526 examples [00:20, 961.30 examples/s]\u001b[A\n","Generating train examples...: 20626 examples [00:21, 971.80 examples/s]\u001b[A\n","Generating train examples...: 20742 examples [00:21, 1023.29 examples/s]\u001b[A\n","Generating train examples...: 20851 examples [00:21, 1041.21 examples/s]\u001b[A\n","Generating train examples...: 20957 examples [00:21, 1039.70 examples/s]\u001b[A\n","Generating train examples...: 21063 examples [00:21, 1045.24 examples/s]\u001b[A\n","Generating train examples...: 21169 examples [00:21, 1034.65 examples/s]\u001b[A\n","Generating train examples...: 21281 examples [00:21, 1057.94 examples/s]\u001b[A\n","Generating train examples...: 21388 examples [00:21, 1040.79 examples/s]\u001b[A\n","Generating train examples...: 21495 examples [00:21, 1046.83 examples/s]\u001b[A\n","Generating train examples...: 21600 examples [00:21, 1030.50 examples/s]\u001b[A\n","Generating train examples...: 21704 examples [00:22, 1021.44 examples/s]\u001b[A\n","Generating train examples...: 21816 examples [00:22, 1049.06 examples/s]\u001b[A\n","Generating train examples...: 21922 examples [00:22, 1044.38 examples/s]\u001b[A\n","Generating train examples...: 22027 examples [00:22, 1045.78 examples/s]\u001b[A\n","Generating train examples...: 22134 examples [00:22, 1052.40 examples/s]\u001b[A\n","Generating train examples...: 22240 examples [00:22, 1048.04 examples/s]\u001b[A\n","Generating train examples...: 22351 examples [00:22, 1064.84 examples/s]\u001b[A\n","Generating train examples...: 22458 examples [00:22, 1041.70 examples/s]\u001b[A\n","Generating train examples...: 22563 examples [00:22, 1014.88 examples/s]\u001b[A\n","Generating train examples...: 22665 examples [00:22, 983.49 examples/s] \u001b[A\n","Generating train examples...: 22772 examples [00:23, 1006.24 examples/s]\u001b[A\n","Generating train examples...: 22882 examples [00:23, 1032.43 examples/s]\u001b[A\n","Generating train examples...: 22986 examples [00:23, 1023.36 examples/s]\u001b[A\n","Generating train examples...: 23090 examples [00:23, 1027.11 examples/s]\u001b[A\n","Generating train examples...: 23195 examples [00:23, 1032.20 examples/s]\u001b[A\n","Generating train examples...: 23299 examples [00:23, 1024.46 examples/s]\u001b[A\n","Generating train examples...: 23408 examples [00:23, 1043.30 examples/s]\u001b[A\n","Generating train examples...: 23513 examples [00:23, 1020.65 examples/s]\u001b[A\n","Generating train examples...: 23616 examples [00:23, 1018.38 examples/s]\u001b[A\n","Generating train examples...: 23720 examples [00:23, 1024.25 examples/s]\u001b[A\n","Generating train examples...: 23825 examples [00:24, 1030.08 examples/s]\u001b[A\n","Generating train examples...: 23936 examples [00:24, 1052.65 examples/s]\u001b[A\n","Generating train examples...: 24042 examples [00:24, 1033.02 examples/s]\u001b[A\n","Generating train examples...: 24149 examples [00:24, 1042.67 examples/s]\u001b[A\n","Generating train examples...: 24257 examples [00:24, 1051.97 examples/s]\u001b[A\n","Generating train examples...: 24363 examples [00:24, 1050.69 examples/s]\u001b[A\n","Generating train examples...: 24474 examples [00:24, 1067.09 examples/s]\u001b[A\n","Generating train examples...: 24581 examples [00:24, 1060.70 examples/s]\u001b[A\n","Generating train examples...: 24690 examples [00:24, 1068.55 examples/s]\u001b[A\n","Generating train examples...: 24797 examples [00:25, 1041.53 examples/s]\u001b[A\n","Generating train examples...: 24904 examples [00:25, 1049.15 examples/s]\u001b[A\n","Generating train examples...: 25013 examples [00:25, 1060.22 examples/s]\u001b[A\n","Generating train examples...: 25120 examples [00:25, 1053.96 examples/s]\u001b[A\n","Generating train examples...: 25226 examples [00:25, 1046.07 examples/s]\u001b[A\n","Generating train examples...: 25331 examples [00:25, 1042.86 examples/s]\u001b[A\n","Generating train examples...: 25436 examples [00:25, 1032.74 examples/s]\u001b[A\n","Generating train examples...: 25540 examples [00:25, 1034.66 examples/s]\u001b[A\n","Generating train examples...: 25648 examples [00:25, 1046.10 examples/s]\u001b[A\n","Generating train examples...: 25753 examples [00:25, 981.99 examples/s] \u001b[A\n","Generating train examples...: 25854 examples [00:26, 987.44 examples/s]\u001b[A\n","Generating train examples...: 25957 examples [00:26, 999.62 examples/s]\u001b[A\n","Generating train examples...: 26061 examples [00:26, 1010.14 examples/s]\u001b[A\n","Generating train examples...: 26171 examples [00:26, 1034.24 examples/s]\u001b[A\n","Generating train examples...: 26281 examples [00:26, 1053.57 examples/s]\u001b[A\n","Generating train examples...: 26388 examples [00:26, 1058.17 examples/s]\u001b[A\n","Generating train examples...: 26495 examples [00:26, 1060.74 examples/s]\u001b[A\n","Generating train examples...: 26602 examples [00:26, 1037.94 examples/s]\u001b[A\n","Generating train examples...: 26706 examples [00:26, 1029.00 examples/s]\u001b[A\n","Generating train examples...: 26813 examples [00:26, 1038.47 examples/s]\u001b[A\n","Generating train examples...: 26917 examples [00:27, 988.75 examples/s] \u001b[A\n","Generating train examples...: 27020 examples [00:27, 999.92 examples/s]\u001b[A\n","Generating train examples...: 27128 examples [00:27, 1022.51 examples/s]\u001b[A\n","Generating train examples...: 27234 examples [00:27, 1032.42 examples/s]\u001b[A\n","Generating train examples...: 27338 examples [00:27, 1025.84 examples/s]\u001b[A\n","Generating train examples...: 27441 examples [00:27, 1019.97 examples/s]\u001b[A\n","Generating train examples...: 27544 examples [00:27, 1021.40 examples/s]\u001b[A\n","Generating train examples...: 27651 examples [00:27, 1034.29 examples/s]\u001b[A\n","Generating train examples...: 27755 examples [00:27, 1031.82 examples/s]\u001b[A\n","Generating train examples...: 27865 examples [00:27, 1049.27 examples/s]\u001b[A\n","Generating train examples...: 27971 examples [00:28, 1052.36 examples/s]\u001b[A\n","Generating train examples...: 28083 examples [00:28, 1071.71 examples/s]\u001b[A\n","Generating train examples...: 28191 examples [00:28, 1071.77 examples/s]\u001b[A\n","Generating train examples...: 28306 examples [00:28, 1092.89 examples/s]\u001b[A\n","Generating train examples...: 28416 examples [00:28, 1053.80 examples/s]\u001b[A\n","Generating train examples...: 28524 examples [00:28, 1060.59 examples/s]\u001b[A\n","Generating train examples...: 28636 examples [00:28, 1075.99 examples/s]\u001b[A\n","Generating train examples...: 28744 examples [00:28, 1057.90 examples/s]\u001b[A\n","Generating train examples...: 28852 examples [00:28, 1063.14 examples/s]\u001b[A\n","Generating train examples...: 28966 examples [00:29, 1083.63 examples/s]\u001b[A\n","Generating train examples...: 29075 examples [00:29, 1083.52 examples/s]\u001b[A\n","Generating train examples...: 29186 examples [00:29, 1091.25 examples/s]\u001b[A\n","Generating train examples...: 29296 examples [00:29, 1091.27 examples/s]\u001b[A\n","Generating train examples...: 29411 examples [00:29, 1107.02 examples/s]\u001b[A\n","Generating train examples...: 29522 examples [00:29, 1098.28 examples/s]\u001b[A\n","Generating train examples...: 29634 examples [00:29, 1103.45 examples/s]\u001b[A\n","Generating train examples...: 29745 examples [00:29, 1069.25 examples/s]\u001b[A\n","Generating train examples...: 29853 examples [00:29, 1056.42 examples/s]\u001b[A\n","Generating train examples...: 29959 examples [00:29, 1035.52 examples/s]\u001b[A\n","Generating train examples...: 30063 examples [00:30, 822.65 examples/s] \u001b[A\n","Generating train examples...: 30164 examples [00:30, 867.86 examples/s]\u001b[A\n","Generating train examples...: 30268 examples [00:30, 911.37 examples/s]\u001b[A\n","Generating train examples...: 30377 examples [00:30, 957.45 examples/s]\u001b[A\n","Generating train examples...: 30477 examples [00:30, 961.73 examples/s]\u001b[A\n","Generating train examples...: 30580 examples [00:30, 979.92 examples/s]\u001b[A\n","Generating train examples...: 30680 examples [00:30, 985.23 examples/s]\u001b[A\n","Generating train examples...: 30783 examples [00:30, 997.59 examples/s]\u001b[A\n","Generating train examples...: 30884 examples [00:30, 990.83 examples/s]\u001b[A\n","Generating train examples...: 30984 examples [00:31, 992.47 examples/s]\u001b[A\n","Generating train examples...: 31084 examples [00:31, 989.66 examples/s]\u001b[A\n","Generating train examples...: 31184 examples [00:31, 978.83 examples/s]\u001b[A\n","Generating train examples...: 31286 examples [00:31, 990.41 examples/s]\u001b[A\n","Generating train examples...: 31387 examples [00:31, 995.03 examples/s]\u001b[A\n","Generating train examples...: 31492 examples [00:31, 1009.77 examples/s]\u001b[A\n","Generating train examples...: 31598 examples [00:31, 1021.84 examples/s]\u001b[A\n","Generating train examples...: 31701 examples [00:31, 1009.19 examples/s]\u001b[A\n","Generating train examples...: 31806 examples [00:31, 1018.78 examples/s]\u001b[A\n","Generating train examples...: 31908 examples [00:31, 1010.91 examples/s]\u001b[A\n","Generating train examples...: 32011 examples [00:32, 1013.85 examples/s]\u001b[A\n","Generating train examples...: 32113 examples [00:32, 1007.27 examples/s]\u001b[A\n","Generating train examples...: 32214 examples [00:32, 1003.90 examples/s]\u001b[A\n","Generating train examples...: 32316 examples [00:32, 1007.72 examples/s]\u001b[A\n","Generating train examples...: 32419 examples [00:32, 1013.73 examples/s]\u001b[A\n","Generating train examples...: 32521 examples [00:32, 1012.19 examples/s]\u001b[A\n","Generating train examples...: 32628 examples [00:32, 1026.76 examples/s]\u001b[A\n","Generating train examples...: 32731 examples [00:32, 1022.10 examples/s]\u001b[A\n","Generating train examples...: 32834 examples [00:32, 1003.66 examples/s]\u001b[A\n","Generating train examples...: 32936 examples [00:32, 1005.43 examples/s]\u001b[A\n","Generating train examples...: 33037 examples [00:33, 1000.90 examples/s]\u001b[A\n","Generating train examples...: 33138 examples [00:33, 980.54 examples/s] \u001b[A\n","Generating train examples...: 33245 examples [00:33, 1005.46 examples/s]\u001b[A\n","Generating train examples...: 33349 examples [00:33, 1013.31 examples/s]\u001b[A\n","Generating train examples...: 33454 examples [00:33, 1021.58 examples/s]\u001b[A\n","Generating train examples...: 33564 examples [00:33, 1044.49 examples/s]\u001b[A\n","Generating train examples...: 33669 examples [00:33, 1032.76 examples/s]\u001b[A\n","Generating train examples...: 33773 examples [00:33, 1026.62 examples/s]\u001b[A\n","Generating train examples...: 33876 examples [00:33, 1024.60 examples/s]\u001b[A\n","Generating train examples...: 33983 examples [00:33, 1036.57 examples/s]\u001b[A\n","Generating train examples...: 34094 examples [00:34, 1057.51 examples/s]\u001b[A\n","Generating train examples...: 34200 examples [00:34, 1018.76 examples/s]\u001b[A\n","Generating train examples...: 34303 examples [00:34, 1010.30 examples/s]\u001b[A\n","Generating train examples...: 34410 examples [00:34, 1026.50 examples/s]\u001b[A\n","Generating train examples...: 34515 examples [00:34, 1031.78 examples/s]\u001b[A\n","Generating train examples...: 34620 examples [00:34, 1035.83 examples/s]\u001b[A\n","Generating train examples...: 34724 examples [00:34, 1027.96 examples/s]\u001b[A\n","Generating train examples...: 34827 examples [00:34, 1018.53 examples/s]\u001b[A\n","Generating train examples...: 34931 examples [00:34, 1024.26 examples/s]\u001b[A\n","Generating train examples...: 35034 examples [00:35, 1006.22 examples/s]\u001b[A\n","Generating train examples...: 35138 examples [00:35, 1016.05 examples/s]\u001b[A\n","Generating train examples...: 35240 examples [00:35, 987.83 examples/s] \u001b[A\n","Generating train examples...: 35341 examples [00:35, 992.55 examples/s]\u001b[A\n","Generating train examples...: 35445 examples [00:35, 1005.01 examples/s]\u001b[A\n","Generating train examples...: 35547 examples [00:35, 1008.56 examples/s]\u001b[A\n","Generating train examples...: 35650 examples [00:35, 1014.85 examples/s]\u001b[A\n","Generating train examples...: 35763 examples [00:35, 1048.20 examples/s]\u001b[A\n","Generating train examples...: 35868 examples [00:35, 1041.30 examples/s]\u001b[A\n","Generating train examples...: 35975 examples [00:35, 1047.24 examples/s]\u001b[A\n","Generating train examples...: 36080 examples [00:36, 1027.59 examples/s]\u001b[A\n","Generating train examples...: 36187 examples [00:36, 1032.70 examples/s]\u001b[A\n","Generating train examples...: 36300 examples [00:36, 1061.02 examples/s]\u001b[A\n","Generating train examples...: 36407 examples [00:36, 1063.64 examples/s]\u001b[A\n","Generating train examples...: 36518 examples [00:36, 1075.33 examples/s]\u001b[A\n","Generating train examples...: 36626 examples [00:36, 1075.41 examples/s]\u001b[A\n","Generating train examples...: 36734 examples [00:36, 1073.12 examples/s]\u001b[A\n","Generating train examples...: 36842 examples [00:36, 1048.39 examples/s]\u001b[A\n","Generating train examples...: 36950 examples [00:36, 1055.82 examples/s]\u001b[A\n","Generating train examples...: 37056 examples [00:36, 1035.36 examples/s]\u001b[A\n","Generating train examples...: 37166 examples [00:37, 1053.90 examples/s]\u001b[A\n","Generating train examples...: 37272 examples [00:37, 1025.34 examples/s]\u001b[A\n","Generating train examples...: 37382 examples [00:37, 1044.31 examples/s]\u001b[A\n","Generating train examples...: 37494 examples [00:37, 1064.51 examples/s]\u001b[A\n","Generating train examples...: 37601 examples [00:37, 1055.34 examples/s]\u001b[A\n","Generating train examples...: 37707 examples [00:37, 1051.02 examples/s]\u001b[A\n","Generating train examples...: 37813 examples [00:37, 1052.23 examples/s]\u001b[A\n","Generating train examples...: 37919 examples [00:37, 1042.92 examples/s]\u001b[A\n","Generating train examples...: 38025 examples [00:37, 1046.47 examples/s]\u001b[A\n","Generating train examples...: 38130 examples [00:37, 1022.56 examples/s]\u001b[A\n","Generating train examples...: 38237 examples [00:38, 1034.79 examples/s]\u001b[A\n","Generating train examples...: 38341 examples [00:38, 981.02 examples/s] \u001b[A\n","Generating train examples...: 38446 examples [00:38, 1000.55 examples/s]\u001b[A\n","Generating train examples...: 38557 examples [00:38, 1030.88 examples/s]\u001b[A\n","Generating train examples...: 38661 examples [00:38, 1024.50 examples/s]\u001b[A\n","Generating train examples...: 38764 examples [00:38, 1019.73 examples/s]\u001b[A\n","Generating train examples...: 38867 examples [00:38, 1008.50 examples/s]\u001b[A\n","Generating train examples...: 38972 examples [00:38, 1018.50 examples/s]\u001b[A\n","Generating train examples...: 39076 examples [00:38, 1024.63 examples/s]\u001b[A\n","Generating train examples...: 39179 examples [00:39, 1016.84 examples/s]\u001b[A\n","Generating train examples...: 39281 examples [00:39, 1008.13 examples/s]\u001b[A\n","Generating train examples...: 39382 examples [00:39, 980.53 examples/s] \u001b[A\n","Generating train examples...: 39487 examples [00:39, 999.96 examples/s]\u001b[A\n","Generating train examples...: 39603 examples [00:39, 1045.44 examples/s]\u001b[A\n","Generating train examples...: 39708 examples [00:39, 1016.72 examples/s]\u001b[A\n","Generating train examples...: 39817 examples [00:39, 1016.91 examples/s]\u001b[A\n","Generating train examples...: 39921 examples [00:39, 1022.22 examples/s]\u001b[A\n","Generating train examples...: 40024 examples [00:39, 835.63 examples/s] \u001b[A\n","Generating train examples...: 40122 examples [00:40, 871.62 examples/s]\u001b[A\n","Generating train examples...: 40228 examples [00:40, 920.18 examples/s]\u001b[A\n","Generating train examples...: 40324 examples [00:40, 925.17 examples/s]\u001b[A\n","Generating train examples...: 40425 examples [00:40, 946.54 examples/s]\u001b[A\n","Generating train examples...: 40535 examples [00:40, 989.04 examples/s]\u001b[A\n","Generating train examples...: 40639 examples [00:40, 1002.17 examples/s]\u001b[A\n","Generating train examples...: 40741 examples [00:40, 1007.33 examples/s]\u001b[A\n","Generating train examples...: 40848 examples [00:40, 1023.04 examples/s]\u001b[A\n","Generating train examples...: 40951 examples [00:40, 1011.97 examples/s]\u001b[A\n","Generating train examples...: 41053 examples [00:40, 1008.85 examples/s]\u001b[A\n","Generating train examples...: 41163 examples [00:41, 1034.81 examples/s]\u001b[A\n","Generating train examples...: 41269 examples [00:41, 1041.54 examples/s]\u001b[A\n","Generating train examples...: 41374 examples [00:41, 1020.31 examples/s]\u001b[A\n","Generating train examples...: 41477 examples [00:41, 1010.84 examples/s]\u001b[A\n","Generating train examples...: 41583 examples [00:41, 1023.72 examples/s]\u001b[A\n","Generating train examples...: 41686 examples [00:41, 1022.78 examples/s]\u001b[A\n","Generating train examples...: 41790 examples [00:41, 1026.58 examples/s]\u001b[A\n","Generating train examples...: 41893 examples [00:41, 1007.49 examples/s]\u001b[A\n","Generating train examples...: 41996 examples [00:41, 1011.62 examples/s]\u001b[A\n","Generating train examples...: 42098 examples [00:41, 1006.54 examples/s]\u001b[A\n","Generating train examples...: 42200 examples [00:42, 1009.06 examples/s]\u001b[A\n","Generating train examples...: 42304 examples [00:42, 1016.35 examples/s]\u001b[A\n","Generating train examples...: 42406 examples [00:42, 1005.30 examples/s]\u001b[A\n","Generating train examples...: 42516 examples [00:42, 1032.59 examples/s]\u001b[A\n","Generating train examples...: 42622 examples [00:42, 1037.84 examples/s]\u001b[A\n","Generating train examples...: 42734 examples [00:42, 1061.44 examples/s]\u001b[A\n","Generating train examples...: 42841 examples [00:42, 1043.68 examples/s]\u001b[A\n","Generating train examples...: 42948 examples [00:42, 1051.28 examples/s]\u001b[A\n","Generating train examples...: 43054 examples [00:42, 1042.83 examples/s]\u001b[A\n","Generating train examples...: 43159 examples [00:43, 1022.55 examples/s]\u001b[A\n","Generating train examples...: 43263 examples [00:43, 1022.79 examples/s]\u001b[A\n","Generating train examples...: 43367 examples [00:43, 1026.75 examples/s]\u001b[A\n","Generating train examples...: 43477 examples [00:43, 1045.88 examples/s]\u001b[A\n","Generating train examples...: 43585 examples [00:43, 1053.76 examples/s]\u001b[A\n","Generating train examples...: 43691 examples [00:43, 1051.25 examples/s]\u001b[A\n","Generating train examples...: 43798 examples [00:43, 1043.49 examples/s]\u001b[A\n","Generating train examples...: 43903 examples [00:43, 1031.90 examples/s]\u001b[A\n","Generating train examples...: 44007 examples [00:43, 1023.84 examples/s]\u001b[A\n","Generating train examples...: 44110 examples [00:43, 1022.23 examples/s]\u001b[A\n","Generating train examples...: 44220 examples [00:44, 1036.35 examples/s]\u001b[A\n","Generating train examples...: 44326 examples [00:44, 1040.75 examples/s]\u001b[A\n","Generating train examples...: 44435 examples [00:44, 1053.52 examples/s]\u001b[A\n","Generating train examples...: 44541 examples [00:44, 1036.05 examples/s]\u001b[A\n","Generating train examples...: 44645 examples [00:44, 1015.27 examples/s]\u001b[A\n","Generating train examples...: 44751 examples [00:44, 1025.90 examples/s]\u001b[A\n","Generating train examples...: 44854 examples [00:44, 1001.54 examples/s]\u001b[A\n","Generating train examples...: 44957 examples [00:44, 1004.89 examples/s]\u001b[A\n","Generating train examples...: 45064 examples [00:44, 1021.96 examples/s]\u001b[A\n","Generating train examples...: 45167 examples [00:44, 1006.03 examples/s]\u001b[A\n","Generating train examples...: 45268 examples [00:45, 1006.76 examples/s]\u001b[A\n","Generating train examples...: 45369 examples [00:45, 989.59 examples/s] \u001b[A\n","Generating train examples...: 45472 examples [00:45, 999.13 examples/s]\u001b[A\n","Generating train examples...: 45573 examples [00:45, 984.37 examples/s]\u001b[A\n","Generating train examples...: 45679 examples [00:45, 1004.96 examples/s]\u001b[A\n","Generating train examples...: 45792 examples [00:45, 1039.96 examples/s]\u001b[A\n","Generating train examples...: 45897 examples [00:45, 1026.80 examples/s]\u001b[A\n","Generating train examples...: 46000 examples [00:45, 1020.14 examples/s]\u001b[A\n","Generating train examples...: 46106 examples [00:45, 1029.54 examples/s]\u001b[A\n","Generating train examples...: 46212 examples [00:45, 1038.38 examples/s]\u001b[A\n","Generating train examples...: 46326 examples [00:46, 1067.93 examples/s]\u001b[A\n","Generating train examples...: 46433 examples [00:46, 1062.61 examples/s]\u001b[A\n","Generating train examples...: 46542 examples [00:46, 1068.97 examples/s]\u001b[A\n","Generating train examples...: 46649 examples [00:46, 992.60 examples/s] \u001b[A\n","Generating train examples...: 46750 examples [00:46, 977.34 examples/s]\u001b[A\n","Generating train examples...: 46853 examples [00:46, 990.35 examples/s]\u001b[A\n","Generating train examples...: 46953 examples [00:46, 989.33 examples/s]\u001b[A\n","Generating train examples...: 47053 examples [00:46, 981.87 examples/s]\u001b[A\n","Generating train examples...: 47159 examples [00:46, 1002.44 examples/s]\u001b[A\n","Generating train examples...: 47261 examples [00:47, 1006.86 examples/s]\u001b[A\n","Generating train examples...: 47363 examples [00:47, 1009.53 examples/s]\u001b[A\n","Generating train examples...: 47466 examples [00:47, 1013.95 examples/s]\u001b[A\n","Generating train examples...: 47568 examples [00:47, 1009.85 examples/s]\u001b[A\n","Generating train examples...: 47670 examples [00:47, 1005.84 examples/s]\u001b[A\n","Generating train examples...: 47771 examples [00:47, 985.56 examples/s] \u001b[A\n","Generating train examples...: 47881 examples [00:47, 1017.18 examples/s]\u001b[A\n","Generating train examples...: 47989 examples [00:47, 1033.54 examples/s]\u001b[A\n","Generating train examples...: 48093 examples [00:47, 1018.28 examples/s]\u001b[A\n","Generating train examples...: 48203 examples [00:47, 1041.60 examples/s]\u001b[A\n","Generating train examples...: 48311 examples [00:48, 1052.67 examples/s]\u001b[A\n","Generating train examples...: 48417 examples [00:48, 1015.13 examples/s]\u001b[A\n","Generating train examples...: 48524 examples [00:48, 1029.69 examples/s]\u001b[A\n","Generating train examples...: 48628 examples [00:48, 995.51 examples/s] \u001b[A\n","Generating train examples...: 48728 examples [00:48, 979.01 examples/s]\u001b[A\n","Generating train examples...: 48827 examples [00:48, 968.55 examples/s]\u001b[A\n","Generating train examples...: 48929 examples [00:48, 982.90 examples/s]\u001b[A\n","Generating train examples...: 49028 examples [00:48, 984.63 examples/s]\u001b[A\n","Generating train examples...: 49127 examples [00:48, 985.20 examples/s]\u001b[A\n","Generating train examples...: 49226 examples [00:48, 986.54 examples/s]\u001b[A\n","Generating train examples...: 49330 examples [00:49, 999.76 examples/s]\u001b[A\n","Generating train examples...: 49439 examples [00:49, 1024.01 examples/s]\u001b[A\n","Generating train examples...: 49544 examples [00:49, 1030.89 examples/s]\u001b[A\n","Generating train examples...: 49650 examples [00:49, 1037.92 examples/s]\u001b[A\n","Generating train examples...: 49756 examples [00:49, 1043.38 examples/s]\u001b[A\n","Generating train examples...: 49861 examples [00:49, 1039.13 examples/s]\u001b[A\n","Generating train examples...: 49965 examples [00:49, 1022.83 examples/s]\u001b[A\n","                                                                        \u001b[A\n","Shuffling cifar35200-train.tfrecord...:   0% 0/50000 [00:00<?, ? examples/s]\u001b[A\n","Shuffling cifar35200-train.tfrecord...:  20% 9753/50000 [00:00<00:00, 97519.86 examples/s]\u001b[A\n","Shuffling cifar35200-train.tfrecord...:  54% 26763/50000 [00:00<00:00, 140208.18 examples/s]\u001b[A\n","Shuffling cifar35200-train.tfrecord...:  88% 43806/50000 [00:00<00:00, 153990.36 examples/s]\u001b[A\n","INFO[tfrecords_writer.py]: Done writing cifar35200-train.tfrecord. Number of examples: 50000 (shards: [50000])\n","Generating splits...:  33% 1/3 [00:50<01:40, 50.14s/ splits]\n","Generating valid examples...: 0 examples [00:00, ? examples/s]\u001b[A\n","Generating valid examples...: 27 examples [00:00, 268.96 examples/s]\u001b[A\n","Generating valid examples...: 135 examples [00:00, 743.53 examples/s]\u001b[A\n","Generating valid examples...: 243 examples [00:00, 895.99 examples/s]\u001b[A\n","Generating valid examples...: 353 examples [00:00, 975.24 examples/s]\u001b[A\n","Generating valid examples...: 463 examples [00:00, 1019.61 examples/s]\u001b[A\n","Generating valid examples...: 565 examples [00:00, 1019.21 examples/s]\u001b[A\n","Generating valid examples...: 670 examples [00:00, 1027.71 examples/s]\u001b[A\n","Generating valid examples...: 774 examples [00:00, 1029.52 examples/s]\u001b[A\n","Generating valid examples...: 877 examples [00:00, 1009.98 examples/s]\u001b[A\n","Generating valid examples...: 979 examples [00:01, 1004.27 examples/s]\u001b[A\n","Generating valid examples...: 1080 examples [00:01, 996.66 examples/s]\u001b[A\n","Generating valid examples...: 1185 examples [00:01, 1012.21 examples/s]\u001b[A\n","Generating valid examples...: 1287 examples [00:01, 980.56 examples/s] \u001b[A\n","Generating valid examples...: 1395 examples [00:01, 1006.74 examples/s]\u001b[A\n","Generating valid examples...: 1499 examples [00:01, 1016.48 examples/s]\u001b[A\n","Generating valid examples...: 1605 examples [00:01, 1027.03 examples/s]\u001b[A\n","Generating valid examples...: 1708 examples [00:01, 1021.08 examples/s]\u001b[A\n","Generating valid examples...: 1815 examples [00:01, 1033.11 examples/s]\u001b[A\n","Generating valid examples...: 1919 examples [00:01, 1011.81 examples/s]\u001b[A\n","Generating valid examples...: 2025 examples [00:02, 1024.16 examples/s]\u001b[A\n","Generating valid examples...: 2137 examples [00:02, 1050.92 examples/s]\u001b[A\n","Generating valid examples...: 2243 examples [00:02, 1033.24 examples/s]\u001b[A\n","Generating valid examples...: 2347 examples [00:02, 1014.78 examples/s]\u001b[A\n","Generating valid examples...: 2449 examples [00:02, 1014.30 examples/s]\u001b[A\n","Generating valid examples...: 2557 examples [00:02, 1031.50 examples/s]\u001b[A\n","Generating valid examples...: 2661 examples [00:02, 1031.15 examples/s]\u001b[A\n","Generating valid examples...: 2765 examples [00:02, 1018.54 examples/s]\u001b[A\n","Generating valid examples...: 2868 examples [00:02, 1009.62 examples/s]\u001b[A\n","Generating valid examples...: 2971 examples [00:02, 1013.20 examples/s]\u001b[A\n","Generating valid examples...: 3073 examples [00:03, 1006.26 examples/s]\u001b[A\n","Generating valid examples...: 3177 examples [00:03, 1014.42 examples/s]\u001b[A\n","Generating valid examples...: 3279 examples [00:03, 1013.24 examples/s]\u001b[A\n","Generating valid examples...: 3382 examples [00:03, 1016.05 examples/s]\u001b[A\n","Generating valid examples...: 3487 examples [00:03, 1017.68 examples/s]\u001b[A\n","Generating valid examples...: 3589 examples [00:03, 1017.99 examples/s]\u001b[A\n","Generating valid examples...: 3697 examples [00:03, 1034.13 examples/s]\u001b[A\n","Generating valid examples...: 3802 examples [00:03, 1037.75 examples/s]\u001b[A\n","Generating valid examples...: 3911 examples [00:03, 1053.13 examples/s]\u001b[A\n","Generating valid examples...: 4017 examples [00:03, 1038.11 examples/s]\u001b[A\n","Generating valid examples...: 4122 examples [00:04, 1040.62 examples/s]\u001b[A\n","Generating valid examples...: 4231 examples [00:04, 1053.38 examples/s]\u001b[A\n","Generating valid examples...: 4337 examples [00:04, 1039.33 examples/s]\u001b[A\n","Generating valid examples...: 4441 examples [00:04, 1002.86 examples/s]\u001b[A\n","Generating valid examples...: 4542 examples [00:04, 984.69 examples/s] \u001b[A\n","Generating valid examples...: 4645 examples [00:04, 995.70 examples/s]\u001b[A\n","Generating valid examples...: 4748 examples [00:04, 1004.82 examples/s]\u001b[A\n","Generating valid examples...: 4849 examples [00:04, 1006.07 examples/s]\u001b[A\n","Generating valid examples...: 4958 examples [00:04, 1028.57 examples/s]\u001b[A\n","Generating valid examples...: 5064 examples [00:05, 1036.53 examples/s]\u001b[A\n","Generating valid examples...: 5169 examples [00:05, 1038.06 examples/s]\u001b[A\n","Generating valid examples...: 5279 examples [00:05, 1053.64 examples/s]\u001b[A\n","Generating valid examples...: 5391 examples [00:05, 1071.18 examples/s]\u001b[A\n","Generating valid examples...: 5499 examples [00:05, 1043.82 examples/s]\u001b[A\n","Generating valid examples...: 5609 examples [00:05, 1058.38 examples/s]\u001b[A\n","Generating valid examples...: 5715 examples [00:05, 1024.59 examples/s]\u001b[A\n","Generating valid examples...: 5821 examples [00:05, 1034.19 examples/s]\u001b[A\n","Generating valid examples...: 5934 examples [00:05, 1059.65 examples/s]\u001b[A\n","Generating valid examples...: 6041 examples [00:05, 1030.69 examples/s]\u001b[A\n","Generating valid examples...: 6147 examples [00:06, 1038.06 examples/s]\u001b[A\n","Generating valid examples...: 6252 examples [00:06, 1037.66 examples/s]\u001b[A\n","Generating valid examples...: 6363 examples [00:06, 1058.70 examples/s]\u001b[A\n","Generating valid examples...: 6470 examples [00:06, 993.49 examples/s] \u001b[A\n","Generating valid examples...: 6571 examples [00:06, 995.31 examples/s]\u001b[A\n","Generating valid examples...: 6684 examples [00:06, 1031.19 examples/s]\u001b[A\n","Generating valid examples...: 6788 examples [00:06, 1033.50 examples/s]\u001b[A\n","Generating valid examples...: 6899 examples [00:06, 1054.44 examples/s]\u001b[A\n","Generating valid examples...: 7005 examples [00:06, 1032.80 examples/s]\u001b[A\n","Generating valid examples...: 7109 examples [00:06, 1027.92 examples/s]\u001b[A\n","Generating valid examples...: 7220 examples [00:07, 1049.59 examples/s]\u001b[A\n","Generating valid examples...: 7326 examples [00:07, 1045.43 examples/s]\u001b[A\n","Generating valid examples...: 7435 examples [00:07, 1057.08 examples/s]\u001b[A\n","Generating valid examples...: 7541 examples [00:07, 1036.59 examples/s]\u001b[A\n","Generating valid examples...: 7645 examples [00:07, 1031.85 examples/s]\u001b[A\n","Generating valid examples...: 7752 examples [00:07, 1038.49 examples/s]\u001b[A\n","Generating valid examples...: 7856 examples [00:07, 1029.01 examples/s]\u001b[A\n","Generating valid examples...: 7963 examples [00:07, 1037.91 examples/s]\u001b[A\n","Generating valid examples...: 8067 examples [00:07, 1030.57 examples/s]\u001b[A\n","Generating valid examples...: 8173 examples [00:08, 1036.82 examples/s]\u001b[A\n","Generating valid examples...: 8283 examples [00:08, 1052.57 examples/s]\u001b[A\n","Generating valid examples...: 8389 examples [00:08, 1030.30 examples/s]\u001b[A\n","Generating valid examples...: 8495 examples [00:08, 1038.61 examples/s]\u001b[A\n","Generating valid examples...: 8599 examples [00:08, 1000.44 examples/s]\u001b[A\n","Generating valid examples...: 8700 examples [00:08, 1002.47 examples/s]\u001b[A\n","Generating valid examples...: 8801 examples [00:08, 993.60 examples/s] \u001b[A\n","Generating valid examples...: 8906 examples [00:08, 1008.01 examples/s]\u001b[A\n","Generating valid examples...: 9013 examples [00:08, 1024.08 examples/s]\u001b[A\n","Generating valid examples...: 9119 examples [00:08, 1033.71 examples/s]\u001b[A\n","Generating valid examples...: 9223 examples [00:09, 1034.60 examples/s]\u001b[A\n","Generating valid examples...: 9330 examples [00:09, 1042.84 examples/s]\u001b[A\n","Generating valid examples...: 9435 examples [00:09, 1025.64 examples/s]\u001b[A\n","Generating valid examples...: 9542 examples [00:09, 1036.01 examples/s]\u001b[A\n","Generating valid examples...: 9646 examples [00:09, 1029.95 examples/s]\u001b[A\n","Generating valid examples...: 9750 examples [00:09, 1013.00 examples/s]\u001b[A\n","Generating valid examples...: 9858 examples [00:09, 1030.35 examples/s]\u001b[A\n","Generating valid examples...: 9962 examples [00:09, 1021.29 examples/s]\u001b[A\n","                                                                       \u001b[A\n","Shuffling cifar35200-valid.tfrecord...:   0% 0/10000 [00:00<?, ? examples/s]\u001b[A\n","INFO[tfrecords_writer.py]: Done writing cifar35200-valid.tfrecord. Number of examples: 10000 (shards: [10000])\n","Generating splits...:  67% 2/3 [00:59<00:26, 26.45s/ splits]\n","Generating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\n","Generating test examples...: 88 examples [00:00, 878.28 examples/s]\u001b[A\n","Generating test examples...: 191 examples [00:00, 966.17 examples/s]\u001b[A\n","Generating test examples...: 304 examples [00:00, 1038.87 examples/s]\u001b[A\n","Generating test examples...: 416 examples [00:00, 1070.34 examples/s]\u001b[A\n","Generating test examples...: 524 examples [00:00, 1064.08 examples/s]\u001b[A\n","Generating test examples...: 631 examples [00:00, 1056.11 examples/s]\u001b[A\n","Generating test examples...: 737 examples [00:00, 1035.21 examples/s]\u001b[A\n","Generating test examples...: 841 examples [00:00, 1030.58 examples/s]\u001b[A\n","Generating test examples...: 951 examples [00:00, 1049.65 examples/s]\u001b[A\n","Generating test examples...: 1057 examples [00:01, 1048.36 examples/s]\u001b[A\n","Generating test examples...: 1171 examples [00:01, 1074.82 examples/s]\u001b[A\n","Generating test examples...: 1279 examples [00:01, 1069.75 examples/s]\u001b[A\n","Generating test examples...: 1387 examples [00:01, 1064.81 examples/s]\u001b[A\n","Generating test examples...: 1494 examples [00:01, 1065.91 examples/s]\u001b[A\n","Generating test examples...: 1601 examples [00:01, 1030.03 examples/s]\u001b[A\n","Generating test examples...: 1705 examples [00:01, 1013.37 examples/s]\u001b[A\n","Generating test examples...: 1810 examples [00:01, 1022.89 examples/s]\u001b[A\n","Generating test examples...: 1913 examples [00:01, 999.48 examples/s] \u001b[A\n","                                                                     \u001b[A\n","Shuffling cifar35200-test.tfrecord...:   0% 0/2000 [00:00<?, ? examples/s]\u001b[A\n","INFO[tfrecords_writer.py]: Done writing cifar35200-test.tfrecord. Number of examples: 2000 (shards: [2000])\n","\u001b[1mDataset cifar35200 downloaded and prepared to /root/tensorflow_datasets/cifar35200/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n","INFO[build.py]: Dataset generation complete...\n","\n","tfds.core.DatasetInfo(\n","    name='cifar35200',\n","    full_name='cifar35200/1.0.0',\n","    description=\"\"\"\n","    \n","    \"\"\",\n","    homepage='https://www.tensorflow.org/datasets/catalog/cifar35200',\n","    data_path='/root/tensorflow_datasets/cifar35200/1.0.0',\n","    download_size=Unknown size,\n","    dataset_size=135.50 MiB,\n","    features=FeaturesDict({\n","        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n","        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n","    }),\n","    supervised_keys=('image', 'label'),\n","    disable_shuffling=False,\n","    splits={\n","        'test': <SplitInfo num_examples=2000, num_shards=1>,\n","        'train': <SplitInfo num_examples=50000, num_shards=1>,\n","        'valid': <SplitInfo num_examples=10000, num_shards=1>,\n","    },\n","    citation=\"\"\"\"\"\",\n",")\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f0gefc6G-A1G","executionInfo":{"status":"ok","timestamp":1634177934220,"user_tz":300,"elapsed":5,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5W-d5yrTmNK52k4FxEIWC7RkPt_KB9gdJgq6YUA=s64","userId":"08509759692231921764"}},"outputId":"b752419a-65d1-41ca-c7c6-8e684b3df7b9"},"source":["# mini test\n","%cd ~\n","import tensorflow_datasets as tfds\n","\n","ds = tfds.load('cifar35200')\n","ds"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/root\n"]},{"output_type":"execute_result","data":{"text/plain":["{'test': <PrefetchDataset shapes: {image: (32, 32, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>,\n"," 'train': <PrefetchDataset shapes: {image: (32, 32, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>,\n"," 'valid': <PrefetchDataset shapes: {image: (32, 32, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>}"]},"metadata":{},"execution_count":620}]},{"cell_type":"markdown","metadata":{"id":"Mnx29rw1Xr2a"},"source":["### Dataset Preprocessing via Transform"]},{"cell_type":"code","metadata":{"id":"1bZtnVYK0YiX"},"source":["import tensorflow.image as transforms\n","import tensorflow_addons as tfa\n","import tensorflow_datasets as tfds\n","\n","from pathlib import Path\n","\n","# don't forget the as_supervised=True, otherwise transformation functions can't find 'image' and 'label' correctly\n","trainset, validset, testset = tfds.load('cifar35200', as_supervised=True, split=['train', 'valid', 'test'])\n","\n","## these are the pytorch transforms. I tried to mimic its behavior, but not exactly the same due to missing functions\n","# transform_train = transforms.Compose([transforms.Resize((32,32)),  #resises the image so it can be perfect for our model.\n","#                                       transforms.RandomHorizontalFlip(), # FLips the image w.r.t horizontal axis\n","#                                       transforms.RandomRotation(10),     #Rotates the image to a specified angel in degrees\n","#                                       transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n","#                                       transforms.ToTensor(), # comvert the image to tensor so that it can work with torch\n","#                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #Normalize all the images\n","#                                       ])\n"," \n","# transform = transforms.Compose([transforms.Resize((32,32)),\n","#                                transforms.ToTensor(),\n","#                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","#                                ])\n","\n","def transform_train(image, label):\n","    image = transforms.resize(image, (32, 32))\n","    image = transforms.random_flip_left_right(image)\n","    image = tfa.image.transform_ops.rotate(image, 0.174533) # angle in radians\n","    image = transforms.random_contrast(image, 0.8, 1.2)\n","    image = transforms.random_saturation(image, 0.8, 1.2)\n","    image = transforms.random_brightness(image, 0.2)\n","    image = transforms.per_image_standardization(image)\n","    return image, label\n","\n","def transform(image, label):\n","    image = transforms.resize(image, (32, 32))\n","    image = transforms.per_image_standardization(image)\n","    return image, label\n","\n","trainset = trainset.map(transform_train).shuffle(1000).batch(BATCH_SIZE)\n","validset = validset.map(transform).batch(BATCH_SIZE)\n","testset = testset.map(transform).batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92RdIqQA6_Ar","executionInfo":{"status":"ok","timestamp":1634178157126,"user_tz":300,"elapsed":2,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5W-d5yrTmNK52k4FxEIWC7RkPt_KB9gdJgq6YUA=s64","userId":"08509759692231921764"}},"outputId":"2fe12e54-26b2-4ea5-e937-36ea89acd8d9"},"source":["trainset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BatchDataset shapes: ((None, 32, 32, 3), (None,)), types: (tf.float32, tf.int64)>"]},"metadata":{},"execution_count":634}]},{"cell_type":"markdown","metadata":{"id":"xwSO-GomvQpl"},"source":["## Define Model"]},{"cell_type":"code","metadata":{"id":"MbqusIzKnGOs"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPool2D\n","from tensorflow.keras import Model\n","\n","class LeNet(Model):\n","  def __init__(self):\n","    super(LeNet, self).__init__()\n","    self.conv1 = Conv2D(16, 3, activation='relu')\n","    self.conv2 = Conv2D(32, 3, activation='relu')\n","    self.conv3 = Conv2D(63, 3, activation='relu')\n","    self.dropout1 = Dropout(0.5)\n","    self.flatten = Flatten()\n","    self.maxpool = MaxPool2D((2,2), 2)\n","    self.fc1 = Dense(500, activation='relu')\n","    self.fc2 = Dense(10)\n","\n","  def call(self, x):\n","    x = self.conv1(x)\n","    x = self.maxpool(x)\n","    x = self.conv2(x)\n","    x = self.maxpool(x)\n","    x = self.conv3(x)\n","    x = self.maxpool(x)\n","    x = self.flatten(x)\n","    x = self.fc1(x)\n","    x = self.dropout1(x)\n","    x = self.fc2(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PfMrklEJx9mM"},"source":["# Create an instance of the model\n","model = LeNet()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HXMJYZfELuR"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"6u42lK4iEdn4"},"source":["learning_rate = 0.001\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AX4QXjBNEjfg"},"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n","valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4BoJfLaElLQ"},"source":["@tf.function\n","def train_step(images, labels):\n","  with tf.GradientTape() as tape:\n","    # training=True is only needed if there are layers with different\n","    # behavior during training versus inference (e.g. Dropout).\n","    predictions = model(images, training=True)\n","    loss = loss_object(labels, predictions)\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_loss(loss)\n","  train_accuracy(labels, predictions)\n","\n","@tf.function\n","def valid_step(images, labels):\n","  # training=False is only needed if there are layers with different\n","  # behavior during training versus inference (e.g. Dropout).\n","  predictions = model(images, training=False)\n","  v_loss = loss_object(labels, predictions)\n","\n","  valid_loss(v_loss)\n","  valid_accuracy(labels, predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480},"id":"YPIZoc1gEm31","executionInfo":{"elapsed":73866,"status":"error","timestamp":1634146878889,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"},"user_tz":300},"outputId":"b57b3f33-2645-42a8-ea57-e3864e8f4e89"},"source":["from tqdm import tqdm\n","\n","for epoch in range(EPOCHS):\n","    # Reset the metrics at the start of the next epoch\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","    valid_loss.reset_states()\n","    valid_accuracy.reset_states()\n","\n","    for images, labels in tqdm(trainset, position=0):\n","        train_step(images, labels)\n","    for images, labels in validset:\n","        valid_step(images, labels)\n","\n","    print('Epoch: %d | Train Loss: %.4f | Train Accuracy: %.4f | Validation Loss: %.4f | Validation Accuracy: %.4f' \\\n","          %(epoch, train_loss.result(), train_accuracy.result() * 100, valid_loss.result(), valid_accuracy.result() * 100))"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1563/1563 [00:21<00:00, 73.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 0 | Train Loss: 0.9756 | Train Accuracy: 65.4140 | Validation Loss: 1.2228 | Validation Accuracy: 59.4100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1563/1563 [00:21<00:00, 74.35it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1 | Train Loss: 0.9413 | Train Accuracy: 66.6540 | Validation Loss: 1.2450 | Validation Accuracy: 58.6400\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1563/1563 [00:22<00:00, 70.30it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2 | Train Loss: 0.9088 | Train Accuracy: 67.8500 | Validation Loss: 1.2439 | Validation Accuracy: 59.8800\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▎       | 368/1563 [00:05<00:17, 66.68it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-69-0e75e011d1ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalid_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2723\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2724\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"ee8KoPUaW0ro"},"source":["## Test score"]},{"cell_type":"code","metadata":{"id":"Jb66Wi4qW0Nm"},"source":["@tf.function\n","def test_step(images, labels):\n","  # training=False is only needed if there are layers with different\n","  # behavior during training versus inference (e.g. Dropout).\n","  predictions = model(images, training=False)\n","  t_loss = loss_object(labels, predictions)\n","\n","  test_loss(t_loss)\n","  test_accuracy(labels, predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fqIQZQ11-LM","executionInfo":{"elapsed":764,"status":"ok","timestamp":1634087203435,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"},"user_tz":300},"outputId":"c65f7127-b93a-468f-fa55-fe0adee6d236"},"source":["for test_images, test_labels in testset:\n","    test_step(test_images, test_labels)\n","\n","print(f'Test Accuracy: {test_accuracy.result() * 100:.2f}')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 51.55\n"]}]},{"cell_type":"markdown","metadata":{"id":"3yhuKsEERtke"},"source":["# Custom Model"]},{"cell_type":"code","metadata":{"id":"lEnUvHq_WqEl"},"source":["import time\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","\n","# leakyrelu layer as activation parameter\n","lrelu = lambda x: tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n","\n","# hyperparameter dict\n","hp_dict = {\n","\t\"optimizer\":[tf.keras.optimizers.SGD(),\n","              tf.keras.optimizers.Adam()],\n","           \n","\t\"activation\":[\"sigmoid\", \"elu\", lrelu, \"relu\", \"swish\", \"tanh\"],\n","           \n","  \"schedule\":['fixed',\n","              tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.002, decay_steps=100000, decay_rate=0.96, name='ExponentialDecay'),\n","              tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate=0.002, decay_steps=100000, alpha=0.0, name='CosineDecay'),\n","              'ReduceOnPlateau'\n","               ],\n","  \"fixed_lr\": 0.02\n","}\n","\n","\n","\n","normalize_mask = np.array([0,0,0,0,1,1,1,1,1,0,1,0]).reshape(3,4)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4wgALX43TJo9"},"source":["def test_hp(optimizer, schedule, schedule_name, activation, fixed_lr, normalize_array, epochs=EPOCHS):\n","  class CustomModel(Model):\n","    def __init__(self):\n","      super(CustomModel, self).__init__()\n","      self.conv1 = Conv2D(16, 3, activation=activation)\n","      self.conv2 = Conv2D(32, 3, activation=activation)\n","      self.conv3 = Conv2D(63, 3, activation=activation)\n","      self.dropout1 = Dropout(0.5)\n","      self.flatten = Flatten()\n","      self.maxpool1 = MaxPool2D((2,2), 2)\n","      self.maxpool2 = MaxPool2D((2,2), 2)\n","      self.maxpool3 = MaxPool2D((2,2), 2)\n","      self.fc1 = Dense(500, activation=activation)\n","      self.fc2 = Dense(10)\n","\n","      self.normalize1 = tf.keras.layers.BatchNormalization()\n","      self.normalize2 = tf.keras.layers.BatchNormalization()\n","      self.normalize3= tf.keras.layers.BatchNormalization()\n","      self.normalize4 = tf.keras.layers.BatchNormalization()\n","\n","\n","    def call(self, x):\n","      x = self.conv1(x)\n","      if normalize_array[0]:\n","        x = self.normalize1(x)\n","      x = self.maxpool1(x)\n","      x = self.conv2(x)\n","      if normalize_array[1]:\n","        x = self.normalize2(x)\n","      x = self.maxpool2(x)\n","      x = self.conv3(x)\n","      if normalize_array[2]:\n","        x = self.normalize3(x)\n","      x = self.maxpool3(x)\n","      x = self.fc1(x)\n","      if normalize_array[3]:\n","        x = self.normalize4(x)\n","      x = self.flatten(x)\n","      x = self.dropout1(x)\n","      x = self.fc2(x)\n","      return x\n","\n","    def model(self):\n","      x_ = tf.keras.Input(shape=(32, 32, 3))\n","      return Model(inputs=[x_], outputs=self.call(x_))\n","  \n","  # compute loss\n","  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","  # init model\n","  model = CustomModel()\n","\n","  # callbacks\n","  call = []\n","\n","  # Early Stopping\n","  stop_early = EarlyStopping(\n","                  monitor=\"val_accuracy\",\n","                  min_delta=1e-4,\n","                  patience=3,\n","                  verbose=2,\n","                  mode=\"auto\",\n","                  baseline=0.15,\n",")\n","\n","  # join optimizer with learning schedule\n","  if schedule == \"ReduceOnPlateau\":\n","    optimizer.learning_rate = fixed_lr\n","    call = [ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.0001)]\n","  elif schedule == \"fixed\":\n","    optimizer.learning_rate = fixed_lr\n","  else:\n","    optimizer.learning_rate = schedule\n","\n","  \n","  call.append(stop_early)\n","\n","  # compile\n","  model.compile(optimizer=optimizer, loss=loss_object, metrics=['accuracy'])\n","  model.build(input_shape=(None, 32, 32, 3))\n","  # model.load_weights(\"/content/drive/MyDrive/Deep Learning System/assignment-2/weights.h5\")\n","  # measure time for each train epoch and each test epoch\n","  t0 = time.time()\n","  history = model.fit(trainset, epochs=epochs, validation_data=validset, callbacks=call)\n","  fit_time = time.time() - t0\n","\n","  t1 = time.time()\n","  # test accuracy\n","  _, test_accuracy = model.evaluate(testset)\n","  test_time = time.time() - t1\n","\n","  return {f'{optimizer._name}_{activation}_{normalize_array}_{schedule}': [fit_time, test_time, test_accuracy, history.history]}\n","\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"I5mezPeqUp4x","executionInfo":{"status":"error","timestamp":1634185937392,"user_tz":300,"elapsed":1985394,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5W-d5yrTmNK52k4FxEIWC7RkPt_KB9gdJgq6YUA=s64","userId":"08509759692231921764"}},"outputId":"91f39eab-5d4b-40df-f52e-a5a2ef165ef0"},"source":["\n","results = {}\n","ses_run = 0\n","for _array in normalize_mask[1:]:\n","  for schedule in hp_dict['schedule']:\n","    for opt in hp_dict['optimizer']:\n","      for act in hp_dict['activation']:\n","\n","        try:\n","          schedule_name = schedule.name\n","        except:\n","          schedule_name = schedule\n","        print(f'----Run {ses_run}----', f'Optimizer: {opt._name}', f'Activation: {act}', f\"Schedule: {schedule_name}\" f'Normalize Array: {_array}', sep='   |   ')\n","        results = {**results,**test_hp(optimizer=opt, schedule=schedule, schedule_name = schedule_name, activation=act, fixed_lr=hp_dict[\"fixed_lr\"], normalize_array=_array, epochs=EPOCHS)}\n","        print('--------\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----Run 0----   |   Optimizer: SGD   |   Activation: sigmoid   |   Schedule: fixedNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.9217 - accuracy: 0.1802 - val_loss: 2.3946 - val_accuracy: 0.1000\n","Epoch 2/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.4767 - accuracy: 0.2544 - val_loss: 2.3897 - val_accuracy: 0.1000\n","Epoch 3/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.3432 - accuracy: 0.2822 - val_loss: 2.3862 - val_accuracy: 0.1000\n","Epoch 00003: early stopping\n","1/1 [==============================] - 0s 261ms/step - loss: 2.3864 - accuracy: 0.1000\n","--------\n","\n","----Run 0----   |   Optimizer: SGD   |   Activation: elu   |   Schedule: fixedNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.9935 - accuracy: 0.1843 - val_loss: 2.2081 - val_accuracy: 0.2367\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.5055 - accuracy: 0.2622 - val_loss: 2.1681 - val_accuracy: 0.2695\n","Epoch 3/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.3347 - accuracy: 0.2954 - val_loss: 2.1378 - val_accuracy: 0.2921\n","Epoch 4/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.2346 - accuracy: 0.3214 - val_loss: 2.1037 - val_accuracy: 0.3013\n","Epoch 5/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.1628 - accuracy: 0.3354 - val_loss: 2.0757 - val_accuracy: 0.3143\n","Epoch 6/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.1033 - accuracy: 0.3485 - val_loss: 2.0378 - val_accuracy: 0.3192\n","Epoch 7/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.0366 - accuracy: 0.3650 - val_loss: 2.0168 - val_accuracy: 0.3223\n","Epoch 8/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.0073 - accuracy: 0.3716 - val_loss: 1.9921 - val_accuracy: 0.3190\n","Epoch 9/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.9496 - accuracy: 0.3842 - val_loss: 1.9749 - val_accuracy: 0.3202\n","Epoch 10/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.9284 - accuracy: 0.3895 - val_loss: 1.9492 - val_accuracy: 0.3276\n","Epoch 11/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.9027 - accuracy: 0.3979 - val_loss: 1.9244 - val_accuracy: 0.3216\n","Epoch 12/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.8623 - accuracy: 0.4067 - val_loss: 1.8969 - val_accuracy: 0.3431\n","Epoch 13/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.8452 - accuracy: 0.4090 - val_loss: 1.8701 - val_accuracy: 0.3476\n","Epoch 14/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.8009 - accuracy: 0.4234 - val_loss: 1.8542 - val_accuracy: 0.3363\n","Epoch 15/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.7913 - accuracy: 0.4258 - val_loss: 1.8318 - val_accuracy: 0.3445\n","1/1 [==============================] - 0s 278ms/step - loss: 2.0103 - accuracy: 0.2695\n","--------\n","\n","----Run 0----   |   Optimizer: SGD   |   Activation: <function <lambda> at 0x7faf5baf67a0>   |   Schedule: fixedNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 3.1418 - accuracy: 0.1652 - val_loss: 2.2745 - val_accuracy: 0.1471\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.6009 - accuracy: 0.2489 - val_loss: 2.2551 - val_accuracy: 0.1603\n","Epoch 3/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.4085 - accuracy: 0.2850 - val_loss: 2.2356 - val_accuracy: 0.1827\n","Epoch 4/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.2884 - accuracy: 0.3082 - val_loss: 2.2174 - val_accuracy: 0.1911\n","Epoch 5/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.1887 - accuracy: 0.3302 - val_loss: 2.1985 - val_accuracy: 0.2147\n","Epoch 6/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.1270 - accuracy: 0.3456 - val_loss: 2.1810 - val_accuracy: 0.2265\n","Epoch 7/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.0624 - accuracy: 0.3576 - val_loss: 2.1625 - val_accuracy: 0.2518\n","Epoch 8/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.0137 - accuracy: 0.3702 - val_loss: 2.1465 - val_accuracy: 0.2665\n","Epoch 9/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.9627 - accuracy: 0.3827 - val_loss: 2.1302 - val_accuracy: 0.2873\n","Epoch 10/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.9282 - accuracy: 0.3896 - val_loss: 2.1144 - val_accuracy: 0.2938\n","Epoch 11/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.9007 - accuracy: 0.3976 - val_loss: 2.0944 - val_accuracy: 0.3155\n","Epoch 12/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.8625 - accuracy: 0.4044 - val_loss: 2.0709 - val_accuracy: 0.3305\n","Epoch 13/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.8233 - accuracy: 0.4125 - val_loss: 2.0482 - val_accuracy: 0.3488\n","Epoch 14/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.8055 - accuracy: 0.4190 - val_loss: 2.0324 - val_accuracy: 0.3556\n","Epoch 15/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.7837 - accuracy: 0.4243 - val_loss: 2.0063 - val_accuracy: 0.3700\n","1/1 [==============================] - 0s 271ms/step - loss: 2.1132 - accuracy: 0.2955\n","--------\n","\n","----Run 0----   |   Optimizer: Adam   |   Activation: sigmoid   |   Schedule: fixedNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 26.6732 - accuracy: 0.1151 - val_loss: 16.2616 - val_accuracy: 0.1137\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 16.3300 - accuracy: 0.1474 - val_loss: 5.8945 - val_accuracy: 0.1000\n","Epoch 3/15\n","7/7 [==============================] - 16s 2s/step - loss: 6.2938 - accuracy: 0.1338 - val_loss: 9.5799 - val_accuracy: 0.1000\n","Epoch 00003: early stopping\n","1/1 [==============================] - 0s 208ms/step - loss: 9.5895 - accuracy: 0.1000\n","--------\n","\n","----Run 0----   |   Optimizer: Adam   |   Activation: elu   |   Schedule: fixedNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 23.3338 - accuracy: 0.1420 - val_loss: 12452.8867 - val_accuracy: 0.1045\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 17.3157 - accuracy: 0.1649 - val_loss: 2433.2029 - val_accuracy: 0.1576\n","Epoch 3/15\n","7/7 [==============================] - 15s 2s/step - loss: 6.7581 - accuracy: 0.1833 - val_loss: 360.7665 - val_accuracy: 0.1119\n","Epoch 4/15\n","7/7 [==============================] - 15s 2s/step - loss: 4.3645 - accuracy: 0.1490 - val_loss: 156.0617 - val_accuracy: 0.1226\n","Epoch 5/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.9680 - accuracy: 0.1873 - val_loss: 42.0286 - val_accuracy: 0.1424\n","Epoch 00005: early stopping\n","1/1 [==============================] - 0s 229ms/step - loss: 43.7851 - accuracy: 0.1225\n","--------\n","\n","----Run 0----   |   Optimizer: Adam   |   Activation: <function <lambda> at 0x7faf5baf67a0>   |   Schedule: fixedNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 21.3591 - accuracy: 0.1375 - val_loss: 7082.0903 - val_accuracy: 0.1643\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 12.7333 - accuracy: 0.1942 - val_loss: 1995.7202 - val_accuracy: 0.1105\n","Epoch 3/15\n","7/7 [==============================] - 15s 2s/step - loss: 5.5081 - accuracy: 0.1605 - val_loss: 787.4872 - val_accuracy: 0.1078\n","Epoch 4/15\n","7/7 [==============================] - 15s 2s/step - loss: 4.7500 - accuracy: 0.1577 - val_loss: 284.9766 - val_accuracy: 0.1655\n","Epoch 5/15\n","7/7 [==============================] - 15s 2s/step - loss: 3.0010 - accuracy: 0.2378 - val_loss: 115.5547 - val_accuracy: 0.1407\n","Epoch 6/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.3685 - accuracy: 0.2200 - val_loss: 58.3330 - val_accuracy: 0.1406\n","Epoch 7/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.1069 - accuracy: 0.2720 - val_loss: 50.3589 - val_accuracy: 0.1123\n","Epoch 00007: early stopping\n","1/1 [==============================] - 0s 228ms/step - loss: 53.1024 - accuracy: 0.1070\n","--------\n","\n","----Run 0----   |   Optimizer: SGD   |   Activation: sigmoid   |   Schedule: ExponentialDecayNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 3.4503 - accuracy: 0.1138 - val_loss: 2.5742 - val_accuracy: 0.1000\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 3.1517 - accuracy: 0.1379 - val_loss: 2.5555 - val_accuracy: 0.1000\n","Epoch 3/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.9859 - accuracy: 0.1568 - val_loss: 2.5385 - val_accuracy: 0.1000\n","Epoch 00003: early stopping\n","1/1 [==============================] - 0s 225ms/step - loss: 2.5386 - accuracy: 0.1000\n","--------\n","\n","----Run 0----   |   Optimizer: SGD   |   Activation: elu   |   Schedule: ExponentialDecayNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 3.6045 - accuracy: 0.1099 - val_loss: 2.2854 - val_accuracy: 0.1225\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 3.2289 - accuracy: 0.1432 - val_loss: 2.2553 - val_accuracy: 0.1505\n","Epoch 3/15\n","7/7 [==============================] - 15s 2s/step - loss: 3.0446 - accuracy: 0.1664 - val_loss: 2.2310 - val_accuracy: 0.1741\n","Epoch 4/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.9174 - accuracy: 0.1870 - val_loss: 2.2098 - val_accuracy: 0.1960\n","Epoch 5/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.8391 - accuracy: 0.2008 - val_loss: 2.1909 - val_accuracy: 0.2155\n","Epoch 6/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.7929 - accuracy: 0.2065 - val_loss: 2.1730 - val_accuracy: 0.2284\n","Epoch 7/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.7305 - accuracy: 0.2159 - val_loss: 2.1555 - val_accuracy: 0.2376\n","Epoch 8/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.6951 - accuracy: 0.2244 - val_loss: 2.1383 - val_accuracy: 0.2479\n","Epoch 9/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.6478 - accuracy: 0.2306 - val_loss: 2.1211 - val_accuracy: 0.2588\n","Epoch 10/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.6042 - accuracy: 0.2405 - val_loss: 2.1043 - val_accuracy: 0.2643\n","Epoch 11/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.5872 - accuracy: 0.2417 - val_loss: 2.0873 - val_accuracy: 0.2693\n","Epoch 12/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.5606 - accuracy: 0.2468 - val_loss: 2.0705 - val_accuracy: 0.2737\n","Epoch 13/15\n","7/7 [==============================] - 16s 2s/step - loss: 2.5235 - accuracy: 0.2535 - val_loss: 2.0533 - val_accuracy: 0.2778\n","Epoch 14/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.5034 - accuracy: 0.2541 - val_loss: 2.0365 - val_accuracy: 0.2832\n","Epoch 15/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.4769 - accuracy: 0.2621 - val_loss: 2.0195 - val_accuracy: 0.2875\n","1/1 [==============================] - 0s 212ms/step - loss: 2.1106 - accuracy: 0.2365\n","--------\n","\n","----Run 0----   |   Optimizer: SGD   |   Activation: <function <lambda> at 0x7faf5baf67a0>   |   Schedule: ExponentialDecayNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 3.7884 - accuracy: 0.0901 - val_loss: 2.3148 - val_accuracy: 0.1151\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 3.4853 - accuracy: 0.1098 - val_loss: 2.3030 - val_accuracy: 0.1293\n","Epoch 3/15\n","7/7 [==============================] - 15s 2s/step - loss: 3.2559 - accuracy: 0.1338 - val_loss: 2.2945 - val_accuracy: 0.1415\n","Epoch 00003: early stopping\n","1/1 [==============================] - 0s 213ms/step - loss: 2.2971 - accuracy: 0.1320\n","--------\n","\n","----Run 0----   |   Optimizer: Adam   |   Activation: sigmoid   |   Schedule: ExponentialDecayNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 3.8422 - accuracy: 0.2155 - val_loss: 2.8189 - val_accuracy: 0.1000\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.6774 - accuracy: 0.3089 - val_loss: 2.7662 - val_accuracy: 0.1000\n","Epoch 3/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.1338 - accuracy: 0.3505 - val_loss: 2.7326 - val_accuracy: 0.1000\n","Epoch 00003: early stopping\n","1/1 [==============================] - 0s 243ms/step - loss: 2.7340 - accuracy: 0.1000\n","--------\n","\n","----Run 0----   |   Optimizer: Adam   |   Activation: elu   |   Schedule: ExponentialDecayNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 3.8959 - accuracy: 0.2287 - val_loss: 3.7643 - val_accuracy: 0.2045\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.5581 - accuracy: 0.3230 - val_loss: 4.0063 - val_accuracy: 0.2245\n","Epoch 3/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.0562 - accuracy: 0.3774 - val_loss: 4.2015 - val_accuracy: 0.2775\n","Epoch 4/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.7742 - accuracy: 0.4168 - val_loss: 3.1014 - val_accuracy: 0.2802\n","Epoch 5/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.6235 - accuracy: 0.4536 - val_loss: 2.8870 - val_accuracy: 0.3122\n","Epoch 6/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.5123 - accuracy: 0.4758 - val_loss: 2.4057 - val_accuracy: 0.3322\n","Epoch 7/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.4402 - accuracy: 0.4986 - val_loss: 1.8794 - val_accuracy: 0.3860\n","Epoch 8/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.3787 - accuracy: 0.5164 - val_loss: 1.8705 - val_accuracy: 0.3900\n","Epoch 9/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.3213 - accuracy: 0.5372 - val_loss: 1.7222 - val_accuracy: 0.4076\n","Epoch 10/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.2864 - accuracy: 0.5479 - val_loss: 1.5738 - val_accuracy: 0.4473\n","Epoch 11/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.2424 - accuracy: 0.5601 - val_loss: 1.5388 - val_accuracy: 0.4617\n","Epoch 12/15\n","7/7 [==============================] - 16s 2s/step - loss: 1.2068 - accuracy: 0.5733 - val_loss: 1.5027 - val_accuracy: 0.4766\n","Epoch 13/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.1822 - accuracy: 0.5832 - val_loss: 1.4666 - val_accuracy: 0.4893\n","Epoch 14/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.1580 - accuracy: 0.5903 - val_loss: 1.4604 - val_accuracy: 0.4895\n","Epoch 15/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.1367 - accuracy: 0.6003 - val_loss: 1.4621 - val_accuracy: 0.4845\n","1/1 [==============================] - 0s 238ms/step - loss: 1.8098 - accuracy: 0.3660\n","--------\n","\n","----Run 0----   |   Optimizer: Adam   |   Activation: <function <lambda> at 0x7faf5baf67a0>   |   Schedule: ExponentialDecayNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 3.4882 - accuracy: 0.2358 - val_loss: 2.2733 - val_accuracy: 0.1893\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.2433 - accuracy: 0.3566 - val_loss: 2.2264 - val_accuracy: 0.2407\n","Epoch 3/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.7836 - accuracy: 0.4261 - val_loss: 2.3780 - val_accuracy: 0.1711\n","Epoch 4/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.5605 - accuracy: 0.4778 - val_loss: 2.1705 - val_accuracy: 0.2151\n","Epoch 5/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.4158 - accuracy: 0.5107 - val_loss: 1.9265 - val_accuracy: 0.3014\n","Epoch 6/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.3238 - accuracy: 0.5417 - val_loss: 1.8505 - val_accuracy: 0.3329\n","Epoch 7/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.2617 - accuracy: 0.5574 - val_loss: 1.7792 - val_accuracy: 0.3635\n","Epoch 8/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.2047 - accuracy: 0.5775 - val_loss: 1.7589 - val_accuracy: 0.3816\n","Epoch 9/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.1589 - accuracy: 0.5928 - val_loss: 1.7656 - val_accuracy: 0.3814\n","Epoch 10/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.1244 - accuracy: 0.6059 - val_loss: 1.7786 - val_accuracy: 0.3722\n","Epoch 11/15\n","7/7 [==============================] - 15s 2s/step - loss: 1.0980 - accuracy: 0.6145 - val_loss: 1.7616 - val_accuracy: 0.3579\n","Epoch 00011: early stopping\n","1/1 [==============================] - 0s 206ms/step - loss: 1.9805 - accuracy: 0.2630\n","--------\n","\n","----Run 0----   |   Optimizer: SGD   |   Activation: sigmoid   |   Schedule: CosineDecayNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 15s 2s/step - loss: 3.6088 - accuracy: 0.1064 - val_loss: 2.7082 - val_accuracy: 0.1000\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 3.1953 - accuracy: 0.1389 - val_loss: 2.6780 - val_accuracy: 0.1000\n","Epoch 3/15\n","7/7 [==============================] - 15s 2s/step - loss: 3.0184 - accuracy: 0.1601 - val_loss: 2.6499 - val_accuracy: 0.1000\n","Epoch 00003: early stopping\n","1/1 [==============================] - 0s 204ms/step - loss: 2.6500 - accuracy: 0.1000\n","--------\n","\n","----Run 0----   |   Optimizer: SGD   |   Activation: elu   |   Schedule: CosineDecayNormalize Array: [1 1 1 1]\n","Epoch 1/15\n","7/7 [==============================] - 16s 2s/step - loss: 3.4117 - accuracy: 0.1263 - val_loss: 2.2820 - val_accuracy: 0.1236\n","Epoch 2/15\n","7/7 [==============================] - 15s 2s/step - loss: 3.1651 - accuracy: 0.1521 - val_loss: 2.2545 - val_accuracy: 0.1460\n","Epoch 3/15\n","7/7 [==============================] - 15s 2s/step - loss: 3.0088 - accuracy: 0.1727 - val_loss: 2.2313 - val_accuracy: 0.1748\n","Epoch 4/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.9066 - accuracy: 0.1869 - val_loss: 2.2099 - val_accuracy: 0.1970\n","Epoch 5/15\n","7/7 [==============================] - 15s 2s/step - loss: 2.8391 - accuracy: 0.1939 - val_loss: 2.1895 - val_accuracy: 0.2178\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x7fb00e84f680>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 546, in __del__\n","    handle=self._handle, deleter=self._deleter)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1264, in delete_iterator\n","    _ctx, \"DeleteIterator\", name, handle, deleter)\n","KeyboardInterrupt: \n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/15\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-675-534ee6751e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mschedule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'----Run {ses_run}----'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Optimizer: {opt._name}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Activation: {act}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Schedule: {schedule_name}\"\u001b[0m \u001b[0;34mf'Normalize Array: {_array}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'   |   '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtest_hp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fixed_lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-674-0ff81aad0dca>\u001b[0m in \u001b[0;36mtest_hp\u001b[0;34m(optimizer, schedule, schedule_name, activation, fixed_lr, normalize_array, epochs)\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;31m# measure time for each train epoch and each test epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m   \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qi3k-14bU6ja","executionInfo":{"status":"ok","timestamp":1634185972661,"user_tz":300,"elapsed":114,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5W-d5yrTmNK52k4FxEIWC7RkPt_KB9gdJgq6YUA=s64","userId":"08509759692231921764"}},"outputId":"0fb460f9-ed1a-4978-d38f-4e6d775066c0"},"source":["results"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Adam_<function <lambda> at 0x7faf5baf67a0>_[1 1 1 1]_<keras.optimizer_v2.learning_rate_schedule.ExponentialDecay object at 0x7faf5555bed0>': [198.09252977371216,\n","  0.3612186908721924,\n","  0.2630000114440918,\n","  {'accuracy': [0.2357800006866455,\n","    0.35662001371383667,\n","    0.42607998847961426,\n","    0.47784000635147095,\n","    0.5106800198554993,\n","    0.5416799783706665,\n","    0.557420015335083,\n","    0.577459990978241,\n","    0.5927799940109253,\n","    0.6058800220489502,\n","    0.6144800186157227],\n","   'loss': [3.488156318664551,\n","    2.2433226108551025,\n","    1.7836476564407349,\n","    1.560499668121338,\n","    1.4157707691192627,\n","    1.3238270282745361,\n","    1.261721134185791,\n","    1.2046840190887451,\n","    1.1588979959487915,\n","    1.1243640184402466,\n","    1.098024845123291],\n","   'val_accuracy': [0.18930000066757202,\n","    0.24070000648498535,\n","    0.17110000550746918,\n","    0.2151000052690506,\n","    0.30140000581741333,\n","    0.3328999876976013,\n","    0.3634999990463257,\n","    0.3815999925136566,\n","    0.3813999891281128,\n","    0.37220001220703125,\n","    0.3578999936580658],\n","   'val_loss': [2.2732858657836914,\n","    2.226351022720337,\n","    2.3780035972595215,\n","    2.170461654663086,\n","    1.9264521598815918,\n","    1.8504825830459595,\n","    1.7791874408721924,\n","    1.7589043378829956,\n","    1.7656171321868896,\n","    1.7785825729370117,\n","    1.7616328001022339]}],\n"," 'Adam_<function <lambda> at 0x7faf5baf67a0>_[1 1 1 1]_fixed': [127.64948654174805,\n","  0.35698914527893066,\n","  0.10700000077486038,\n","  {'accuracy': [0.13745999336242676,\n","    0.19422000646591187,\n","    0.1604599952697754,\n","    0.15771999955177307,\n","    0.2377600073814392,\n","    0.21998000144958496,\n","    0.2720400094985962],\n","   'loss': [21.359071731567383,\n","    12.733255386352539,\n","    5.508094787597656,\n","    4.74995756149292,\n","    3.000981569290161,\n","    2.368474006652832,\n","    2.1069085597991943],\n","   'val_accuracy': [0.16429999470710754,\n","    0.11050000041723251,\n","    0.10779999941587448,\n","    0.1655000001192093,\n","    0.14069999754428864,\n","    0.14059999585151672,\n","    0.11230000108480453],\n","   'val_loss': [7082.09033203125,\n","    1995.72021484375,\n","    787.4872436523438,\n","    284.9765625,\n","    115.5546646118164,\n","    58.33304977416992,\n","    50.3588981628418]}],\n"," 'Adam_elu_[1 1 1 1]_<keras.optimizer_v2.learning_rate_schedule.ExponentialDecay object at 0x7faf5555bed0>': [297.63467741012573,\n","  0.2530252933502197,\n","  0.3659999966621399,\n","  {'accuracy': [0.22871999442577362,\n","    0.32297998666763306,\n","    0.3774400055408478,\n","    0.4168199896812439,\n","    0.45361998677253723,\n","    0.47576001286506653,\n","    0.4985800087451935,\n","    0.5163999795913696,\n","    0.5371599793434143,\n","    0.5479199886322021,\n","    0.5601199865341187,\n","    0.5733000040054321,\n","    0.5831599831581116,\n","    0.5903199911117554,\n","    0.6003199815750122],\n","   'loss': [3.895949125289917,\n","    2.558103322982788,\n","    2.0562045574188232,\n","    1.7741587162017822,\n","    1.6235109567642212,\n","    1.512254238128662,\n","    1.4401947259902954,\n","    1.378718614578247,\n","    1.3213192224502563,\n","    1.2863867282867432,\n","    1.2423772811889648,\n","    1.2067670822143555,\n","    1.1821633577346802,\n","    1.1580348014831543,\n","    1.1367125511169434],\n","   'val_accuracy': [0.2045000046491623,\n","    0.22450000047683716,\n","    0.2775000035762787,\n","    0.2802000045776367,\n","    0.31220000982284546,\n","    0.33219999074935913,\n","    0.38600000739097595,\n","    0.38999998569488525,\n","    0.4075999855995178,\n","    0.447299987077713,\n","    0.4616999924182892,\n","    0.4765999913215637,\n","    0.489300012588501,\n","    0.4894999861717224,\n","    0.484499990940094],\n","   'val_loss': [3.7643227577209473,\n","    4.006252765655518,\n","    4.201519966125488,\n","    3.1013505458831787,\n","    2.8870184421539307,\n","    2.405688762664795,\n","    1.879368782043457,\n","    1.87050199508667,\n","    1.722216010093689,\n","    1.5737539529800415,\n","    1.5388263463974,\n","    1.502712607383728,\n","    1.466637372970581,\n","    1.46038019657135,\n","    1.4620964527130127]}],\n"," 'Adam_elu_[1 1 1 1]_fixed': [81.62985706329346,\n","  0.24355554580688477,\n","  0.12250000238418579,\n","  {'accuracy': [0.14203999936580658,\n","    0.164900004863739,\n","    0.18333999812602997,\n","    0.14903999865055084,\n","    0.1872600018978119],\n","   'loss': [23.333757400512695,\n","    17.31565284729004,\n","    6.758101463317871,\n","    4.364531517028809,\n","    2.968047618865967],\n","   'val_accuracy': [0.10450000315904617,\n","    0.15760000050067902,\n","    0.11190000176429749,\n","    0.1225999966263771,\n","    0.14239999651908875],\n","   'val_loss': [12452.88671875,\n","    2433.202880859375,\n","    360.7664794921875,\n","    156.06167602539062,\n","    42.028568267822266]}],\n"," 'Adam_sigmoid_[1 1 1 1]_<keras.optimizer_v2.learning_rate_schedule.ExponentialDecay object at 0x7faf5555bed0>': [51.61708617210388,\n","  0.26236701011657715,\n","  0.10000000149011612,\n","  {'accuracy': [0.2155199944972992, 0.30893999338150024, 0.35054001212120056],\n","   'loss': [3.8422491550445557, 2.6773810386657715, 2.1337926387786865],\n","   'val_accuracy': [0.10000000149011612,\n","    0.10000000149011612,\n","    0.10000000149011612],\n","   'val_loss': [2.8188881874084473, 2.7661936283111572, 2.7325782775878906]}],\n"," 'Adam_sigmoid_[1 1 1 1]_fixed': [57.52242827415466,\n","  0.3651728630065918,\n","  0.10000000149011612,\n","  {'accuracy': [0.11509999632835388, 0.14737999439239502, 0.13379999995231628],\n","   'loss': [26.67316436767578, 16.329959869384766, 6.293848037719727],\n","   'val_accuracy': [0.1137000024318695,\n","    0.10000000149011612,\n","    0.10000000149011612],\n","   'val_loss': [16.261621475219727, 5.894517421722412, 9.57989501953125]}],\n"," 'SGD_<function <lambda> at 0x7faf5baf67a0>_[1 1 1 1]_<keras.optimizer_v2.learning_rate_schedule.ExponentialDecay object at 0x7faf5555bed0>': [51.767306089401245,\n","  0.2251570224761963,\n","  0.13199999928474426,\n","  {'accuracy': [0.09012000262737274, 0.10982000082731247, 0.133760005235672],\n","   'loss': [3.788374423980713, 3.485276460647583, 3.2559397220611572],\n","   'val_accuracy': [0.11509999632835388,\n","    0.12929999828338623,\n","    0.14149999618530273],\n","   'val_loss': [2.314804792404175, 2.3030154705047607, 2.294546365737915]}],\n"," 'SGD_<function <lambda> at 0x7faf5baf67a0>_[1 1 1 1]_fixed': [269.99136304855347,\n","  0.3582792282104492,\n","  0.2955000102519989,\n","  {'accuracy': [0.1651799976825714,\n","    0.24886000156402588,\n","    0.2850399911403656,\n","    0.3081600069999695,\n","    0.3301999866962433,\n","    0.3455600142478943,\n","    0.3576200008392334,\n","    0.3701600134372711,\n","    0.3827199935913086,\n","    0.38958001136779785,\n","    0.39757999777793884,\n","    0.40441998839378357,\n","    0.41251999139785767,\n","    0.41901999711990356,\n","    0.4243200123310089],\n","   'loss': [3.141848087310791,\n","    2.600921154022217,\n","    2.408463478088379,\n","    2.2883572578430176,\n","    2.1886861324310303,\n","    2.1269583702087402,\n","    2.062429189682007,\n","    2.0137388706207275,\n","    1.9626920223236084,\n","    1.9282182455062866,\n","    1.9007296562194824,\n","    1.862504005432129,\n","    1.8233062028884888,\n","    1.805455207824707,\n","    1.783742070198059],\n","   'val_accuracy': [0.14710000157356262,\n","    0.16030000150203705,\n","    0.1826999932527542,\n","    0.19110000133514404,\n","    0.21469999849796295,\n","    0.226500004529953,\n","    0.251800000667572,\n","    0.26649999618530273,\n","    0.2872999906539917,\n","    0.2937999963760376,\n","    0.3154999911785126,\n","    0.3305000066757202,\n","    0.34880000352859497,\n","    0.3555999994277954,\n","    0.3700000047683716],\n","   'val_loss': [2.2745370864868164,\n","    2.2550902366638184,\n","    2.235588550567627,\n","    2.217432737350464,\n","    2.1984713077545166,\n","    2.1810314655303955,\n","    2.1625254154205322,\n","    2.146512269973755,\n","    2.130155324935913,\n","    2.1143553256988525,\n","    2.0943667888641357,\n","    2.0708680152893066,\n","    2.0481793880462646,\n","    2.032447576522827,\n","    2.006265640258789]}],\n"," 'SGD_elu_[1 1 1 1]_<keras.optimizer_v2.learning_rate_schedule.ExponentialDecay object at 0x7faf5555bed0>': [275.6884570121765,\n","  0.3598134517669678,\n","  0.23649999499320984,\n","  {'accuracy': [0.10989999771118164,\n","    0.14319999516010284,\n","    0.16641999781131744,\n","    0.1869799941778183,\n","    0.20076000690460205,\n","    0.2064799964427948,\n","    0.21592000126838684,\n","    0.22436000406742096,\n","    0.23056000471115112,\n","    0.24053999781608582,\n","    0.24169999361038208,\n","    0.24677999317646027,\n","    0.25352001190185547,\n","    0.2541399896144867,\n","    0.26212000846862793],\n","   'loss': [3.604494333267212,\n","    3.2289443016052246,\n","    3.0446412563323975,\n","    2.9174418449401855,\n","    2.8390893936157227,\n","    2.7929458618164062,\n","    2.730532169342041,\n","    2.6950647830963135,\n","    2.6477980613708496,\n","    2.604196786880493,\n","    2.5871753692626953,\n","    2.560614585876465,\n","    2.5235233306884766,\n","    2.5034122467041016,\n","    2.4768896102905273],\n","   'val_accuracy': [0.12250000238418579,\n","    0.15049999952316284,\n","    0.17409999668598175,\n","    0.19599999487400055,\n","    0.21549999713897705,\n","    0.22840000689029694,\n","    0.23759999871253967,\n","    0.24789999425411224,\n","    0.2587999999523163,\n","    0.26429998874664307,\n","    0.26930001378059387,\n","    0.2736999988555908,\n","    0.2777999937534332,\n","    0.2831999957561493,\n","    0.2874999940395355],\n","   'val_loss': [2.285433053970337,\n","    2.2553250789642334,\n","    2.231049060821533,\n","    2.2097995281219482,\n","    2.190889596939087,\n","    2.172957181930542,\n","    2.155466318130493,\n","    2.1382617950439453,\n","    2.121108293533325,\n","    2.104278326034546,\n","    2.087327241897583,\n","    2.070521354675293,\n","    2.053309440612793,\n","    2.0365359783172607,\n","    2.0194671154022217]}],\n"," 'SGD_elu_[1 1 1 1]_fixed': [269.241667509079,\n","  0.369342565536499,\n","  0.2694999873638153,\n","  {'accuracy': [0.18432000279426575,\n","    0.2621999979019165,\n","    0.2953999936580658,\n","    0.3213599920272827,\n","    0.33535999059677124,\n","    0.3484799861907959,\n","    0.3649600148200989,\n","    0.37158000469207764,\n","    0.38420000672340393,\n","    0.38951998949050903,\n","    0.3979400098323822,\n","    0.40667998790740967,\n","    0.40904000401496887,\n","    0.4233799874782562,\n","    0.425819993019104],\n","   'loss': [2.9935302734375,\n","    2.5055313110351562,\n","    2.3347418308258057,\n","    2.234618663787842,\n","    2.1627869606018066,\n","    2.1032559871673584,\n","    2.0366127490997314,\n","    2.0073087215423584,\n","    1.9495761394500732,\n","    1.9284279346466064,\n","    1.9027215242385864,\n","    1.862297534942627,\n","    1.8452290296554565,\n","    1.8008787631988525,\n","    1.7912877798080444],\n","   'val_accuracy': [0.23669999837875366,\n","    0.2694999873638153,\n","    0.2921000123023987,\n","    0.3012999892234802,\n","    0.314300000667572,\n","    0.3192000091075897,\n","    0.322299987077713,\n","    0.3190000057220459,\n","    0.32019999623298645,\n","    0.32760000228881836,\n","    0.3215999901294708,\n","    0.34310001134872437,\n","    0.3476000130176544,\n","    0.33629998564720154,\n","    0.34450000524520874],\n","   'val_loss': [2.208061933517456,\n","    2.168090343475342,\n","    2.137793779373169,\n","    2.103687286376953,\n","    2.0756516456604004,\n","    2.0377984046936035,\n","    2.016810178756714,\n","    1.9921196699142456,\n","    1.9749428033828735,\n","    1.9491667747497559,\n","    1.9243539571762085,\n","    1.8969480991363525,\n","    1.870102882385254,\n","    1.8541960716247559,\n","    1.8318066596984863]}],\n"," 'SGD_sigmoid_[1 1 1 1]_<keras.optimizer_v2.learning_rate_schedule.CosineDecay object at 0x7faf5555b6d0>': [51.09837985038757,\n","  0.21725749969482422,\n","  0.10000000149011612,\n","  {'accuracy': [0.10639999806880951, 0.1389400064945221, 0.16008000075817108],\n","   'loss': [3.6088247299194336, 3.1952695846557617, 3.0184366703033447],\n","   'val_accuracy': [0.10000000149011612,\n","    0.10000000149011612,\n","    0.10000000149011612],\n","   'val_loss': [2.7081916332244873, 2.6780242919921875, 2.649914026260376]}],\n"," 'SGD_sigmoid_[1 1 1 1]_<keras.optimizer_v2.learning_rate_schedule.ExponentialDecay object at 0x7faf5555bed0>': [57.01253271102905,\n","  0.2386798858642578,\n","  0.10000000149011612,\n","  {'accuracy': [0.1138399988412857, 0.13792000710964203, 0.1568399965763092],\n","   'loss': [3.4503207206726074, 3.1517441272735596, 2.985938549041748],\n","   'val_accuracy': [0.10000000149011612,\n","    0.10000000149011612,\n","    0.10000000149011612],\n","   'val_loss': [2.574174642562866, 2.5554866790771484, 2.538534641265869]}],\n"," 'SGD_sigmoid_[1 1 1 1]_fixed': [53.03798532485962,\n","  0.36585307121276855,\n","  0.10000000149011612,\n","  {'accuracy': [0.18016000092029572, 0.25435999035835266, 0.28224000334739685],\n","   'loss': [2.921696662902832, 2.4767446517944336, 2.3432374000549316],\n","   'val_accuracy': [0.10000000149011612,\n","    0.10000000149011612,\n","    0.10000000149011612],\n","   'val_loss': [2.394561290740967, 2.389708995819092, 2.3861677646636963]}]}"]},"metadata":{},"execution_count":676}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Ygw6mybWfyv","executionInfo":{"status":"ok","timestamp":1634158056798,"user_tz":300,"elapsed":171,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"}},"outputId":"615ce618-3108-4dc0-aa8e-c3737fcf0a39"},"source":["model_.,pde;summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_14 (InputLayer)        [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv2d_149 (Conv2D)          (None, 30, 30, 16)        448       \n","_________________________________________________________________\n","max_pooling2d_51 (MaxPooling (None, 15, 15, 16)        0         \n","_________________________________________________________________\n","conv2d_150 (Conv2D)          (None, 13, 13, 32)        4640      \n","_________________________________________________________________\n","max_pooling2d_52 (MaxPooling (None, 6, 6, 32)          0         \n","_________________________________________________________________\n","conv2d_151 (Conv2D)          (None, 4, 4, 63)          18207     \n","_________________________________________________________________\n","max_pooling2d_53 (MaxPooling (None, 2, 2, 63)          0         \n","_________________________________________________________________\n","flatten_49 (Flatten)         (None, 252)               0         \n","_________________________________________________________________\n","dense_98 (Dense)             (None, 500)               126500    \n","_________________________________________________________________\n","dropout_49 (Dropout)         (None, 500)               0         \n","_________________________________________________________________\n","dense_99 (Dense)             (None, 10)                5010      \n","=================================================================\n","Total params: 154,805\n","Trainable params: 154,805\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"rOnAGPgNfVIP"},"source":["initial_learning_rate = 0.1\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=100000,\n","    decay_rate=0.96,\n","    staircase=True)\n","\n","model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule),\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(data, labels, epochs=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8H2ApAGxLCik"},"source":["x = tf.keras.optimizers.SGD(name='SGD')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aqs-noFxLE24","executionInfo":{"status":"ok","timestamp":1634170857553,"user_tz":300,"elapsed":176,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"}},"outputId":"7034f46a-fae9-425a-e0a1-e21de59d1ac5"},"source":["x.learning_rate"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>"]},"metadata":{},"execution_count":498}]},{"cell_type":"code","metadata":{"id":"vo3G0DfILFev"},"source":["x.learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.1, decay_steps=100000, decay_rate=0.96)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkYtggeWLLuW","executionInfo":{"status":"ok","timestamp":1634170959666,"user_tz":300,"elapsed":7,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"}},"outputId":"2397612e-6055-48e9-8a2d-825785283de2"},"source":["x"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.optimizer_v2.gradient_descent.SGD at 0x7faf55824d10>"]},"metadata":{},"execution_count":505}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAjpPP-LLfWS","executionInfo":{"status":"ok","timestamp":1634170963106,"user_tz":300,"elapsed":117,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"}},"outputId":"401fc024-e47f-43c2-eefa-76689fdc61c8"},"source":["x.learning_rate"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.optimizer_v2.learning_rate_schedule.ExponentialDecay at 0x7faf556fee50>"]},"metadata":{},"execution_count":506}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzol0KVVLgMp","executionInfo":{"status":"ok","timestamp":1634171344231,"user_tz":300,"elapsed":105,"user":{"displayName":"Sebastián Barrios Slight","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSrRx4NzancgiJXyPBjlM4VNrFUhSHeYER_ICtlA=s64","userId":"08509759692231921764"}},"outputId":"f88a3363-6c8e-4168-fba8-6bf2a83390ed"},"source":[""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'decay_rate': 0.96,\n"," 'decay_steps': 100000,\n"," 'initial_learning_rate': 0.1,\n"," 'name': None,\n"," 'staircase': False}"]},"metadata":{},"execution_count":530}]},{"cell_type":"code","metadata":{"id":"NDVz_PrjMZft"},"source":[""],"execution_count":null,"outputs":[]}]}