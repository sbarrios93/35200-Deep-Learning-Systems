{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the training more efficient, the original Jupyter notebook was split and converted into a python script. The model was trained in a DataCrunch cloud environment with an A6000 GPU.\n",
    "\n",
    "The repo for this model is [here](https://github.com/sbarrios93/35200-Deep-Learning-Systems/tree/main/hw-3).\n",
    "\n",
    "The checkpoint files are not included because they are too large for the github repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: run the baseline model, understand what it's doing and make sure it works\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Baseline Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.16%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('metrics/epoch-base.json', 'r') as f:\n",
    "    base = json.load(f)\n",
    "\n",
    "print(f\"{'{:.2%}'.format(base['10']['accuracies'][-1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Baseline Loss:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7070708870887756\n"
     ]
    }
   ],
   "source": [
    "print(base['10']['losses'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How long did it take to train? (use `%%time` to measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.6 min\n"
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "for k in base['10']['epoch_times'].keys():\n",
    "    total_time += float(k)\n",
    "print(f\"{'{:.3}'.format(total_time/60)} min\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Experiment with changing the following:\n",
    "\n",
    "For each experiment where you vary hyperparameters use **at least three different values**.\n",
    "\n",
    "Explain the results you get **in terms of your understanding of transformers**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>dim-256</th>\n",
       "      <th>dim-1024</th>\n",
       "      <th>dim-2048</th>\n",
       "      <th>depth-2</th>\n",
       "      <th>depth-6</th>\n",
       "      <th>depth-10</th>\n",
       "      <th>heads-2</th>\n",
       "      <th>heads-4</th>\n",
       "      <th>heads-16</th>\n",
       "      <th>vocab</th>\n",
       "      <th>skip-positional</th>\n",
       "      <th>gelu</th>\n",
       "      <th>swish</th>\n",
       "      <th>ger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAX_VOCAB_SIZE</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>8192</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_MODEL</th>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>1024</td>\n",
       "      <td>2048</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_LAYERS</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FFN_UNITS</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_HEADS</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DROPOUT_RATE</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACTIVATION</th>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>swish</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USE_POSITIONAL</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_SAMPLES</th>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX_LENGTH</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPOCHS</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANG</th>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>SPA</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 base dim-256 dim-1024 dim-2048 depth-2 depth-6 depth-10  \\\n",
       "MAX_VOCAB_SIZE  16384   16384    16384    16384   16384   16384    16384   \n",
       "D_MODEL           512     256     1024     2048     512     512      512   \n",
       "N_LAYERS            4       4        4        4       2       6       10   \n",
       "FFN_UNITS         512     512      512      512     512     512      512   \n",
       "N_HEADS             8       8        8        8       8       8        8   \n",
       "DROPOUT_RATE      0.1     0.1      0.1      0.1     0.1     0.1      0.1   \n",
       "ACTIVATION       relu    relu     relu     relu    relu    relu     relu   \n",
       "USE_POSITIONAL   True    True     True     True    True    True     True   \n",
       "NUM_SAMPLES     80000   80000    80000    80000   80000   80000    80000   \n",
       "MAX_LENGTH         15      15       15       15      15      15       15   \n",
       "EPOCHS             10      10       10       10      10      10       10   \n",
       "LANG              SPA     SPA      SPA      SPA     SPA     SPA      SPA   \n",
       "\n",
       "               heads-2 heads-4 heads-16  vocab skip-positional   gelu  swish  \\\n",
       "MAX_VOCAB_SIZE   16384   16384    16384   8192           16384  16384  16384   \n",
       "D_MODEL            512     512      512    512             512    512    512   \n",
       "N_LAYERS             4       4        4      4               4      4      4   \n",
       "FFN_UNITS          512     512      512    512             512    512    512   \n",
       "N_HEADS              2       4       16      8               8      8      8   \n",
       "DROPOUT_RATE       0.1     0.1      0.1    0.1             0.1    0.1    0.1   \n",
       "ACTIVATION        relu    relu     relu   relu            relu   gelu  swish   \n",
       "USE_POSITIONAL    True    True     True   True           False   True   True   \n",
       "NUM_SAMPLES      80000   80000    80000  80000           80000  80000  80000   \n",
       "MAX_LENGTH          15      15       15     15              15     15     15   \n",
       "EPOCHS              10      10       10     10              10     10     10   \n",
       "LANG               SPA     SPA      SPA    SPA             SPA    SPA    SPA   \n",
       "\n",
       "                  ger  \n",
       "MAX_VOCAB_SIZE  16384  \n",
       "D_MODEL           512  \n",
       "N_LAYERS            4  \n",
       "FFN_UNITS         512  \n",
       "N_HEADS             8  \n",
       "DROPOUT_RATE      0.1  \n",
       "ACTIVATION       relu  \n",
       "USE_POSITIONAL   True  \n",
       "NUM_SAMPLES     80000  \n",
       "MAX_LENGTH         15  \n",
       "EPOCHS             10  \n",
       "LANG               DE  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "with open('conf.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "models = pd.DataFrame(config['MODELS'])\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>dim-256</th>\n",
       "      <th>dim-1024</th>\n",
       "      <th>dim-2048</th>\n",
       "      <th>depth-2</th>\n",
       "      <th>depth-6</th>\n",
       "      <th>depth-10</th>\n",
       "      <th>heads-2</th>\n",
       "      <th>heads-4</th>\n",
       "      <th>heads-16</th>\n",
       "      <th>vocab</th>\n",
       "      <th>skip-positional</th>\n",
       "      <th>gelu</th>\n",
       "      <th>swish</th>\n",
       "      <th>ger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracies</th>\n",
       "      <td>37.16%</td>\n",
       "      <td>37.54%</td>\n",
       "      <td>35.61%</td>\n",
       "      <td>31.70%</td>\n",
       "      <td>40.26%</td>\n",
       "      <td>34.22%</td>\n",
       "      <td>20.30%</td>\n",
       "      <td>36.30%</td>\n",
       "      <td>36.71%</td>\n",
       "      <td>37.31%</td>\n",
       "      <td>39.78%</td>\n",
       "      <td>37.10%</td>\n",
       "      <td>37.39%</td>\n",
       "      <td>37.55%</td>\n",
       "      <td>36.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.712541</td>\n",
       "      <td>0.788699</td>\n",
       "      <td>1.016393</td>\n",
       "      <td>0.515611</td>\n",
       "      <td>0.881567</td>\n",
       "      <td>1.668171</td>\n",
       "      <td>0.763804</td>\n",
       "      <td>0.737258</td>\n",
       "      <td>0.698448</td>\n",
       "      <td>0.597807</td>\n",
       "      <td>0.713013</td>\n",
       "      <td>0.692861</td>\n",
       "      <td>0.681648</td>\n",
       "      <td>0.536454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_time_in_min</th>\n",
       "      <td>37.6</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>86.9</td>\n",
       "      <td>37.2</td>\n",
       "      <td>37.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>38.7</td>\n",
       "      <td>37.7</td>\n",
       "      <td>39.2</td>\n",
       "      <td>38.6</td>\n",
       "      <td>38.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       base   dim-256  dim-1024  dim-2048   depth-2   depth-6  \\\n",
       "accuracies           37.16%    37.54%    35.61%    31.70%    40.26%    34.22%   \n",
       "losses             0.707071  0.712541  0.788699  1.016393  0.515611  0.881567   \n",
       "total_time_in_min      37.6      38.0      39.0      38.3      21.0      53.1   \n",
       "\n",
       "                   depth-10   heads-2   heads-4  heads-16     vocab  \\\n",
       "accuracies           20.30%    36.30%    36.71%    37.31%    39.78%   \n",
       "losses             1.668171  0.763804  0.737258  0.698448  0.597807   \n",
       "total_time_in_min      86.9      37.2      37.4      38.8      38.7   \n",
       "\n",
       "                  skip-positional      gelu     swish       ger  \n",
       "accuracies                 37.10%    37.39%    37.55%    36.30%  \n",
       "losses                   0.713013  0.692861  0.681648  0.536454  \n",
       "total_time_in_min            37.7      39.2      38.6      38.1  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob \n",
    "\n",
    "metrics = glob.glob('metrics/epoch-*.json')\n",
    "\n",
    "metric_dict = {}\n",
    "\n",
    "for path in metrics:\n",
    "    total_time = 0 \n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        name = path.split('epoch-')[-1].split('.json')[0]\n",
    "        accuracies = '{:.2%}'.format(data['10']['accuracies'][-1])\n",
    "        losses = data['10']['losses'][-1]\n",
    "        for k in data['10']['epoch_times'].keys():\n",
    "            total_time += float(k)\n",
    "        total_time = '{:.3}'.format(total_time/60)\n",
    "    metric_dict[name] = [accuracies, losses, total_time]\n",
    "        \n",
    "metrics_df = pd.DataFrame(metric_dict, index=['accuracies', 'losses', 'total_time_in_min'])\n",
    "metrics_df = metrics_df[models.columns.tolist()]\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the values from the baseline model didn't bring much benefits to the accuracy or loss. Neither to the time it took to train. Depth was the highest driver of variability on the acurracy and training time. Decreasing the depth of the model to 1 increase the accuracy by 3.2 percentage points and also decreased the training time in 16.6 minutes. In contrast, increaseing depth all the way to 10 strongly hurt the accuracy (decreasing to 20.3%) and increased the training time in 49.3 minutes.\n",
    "\n",
    "I wonder if training on a larger dataset and vocabulary size would help. \n",
    "\n",
    "Furthermore, skipping the positional encoding didn't either do much. The skip-positional model has almost the same metrics than the baseline. Gelu and Swish didn't do much either. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: compare ReLU against GELU & Swish\n",
    "Compare the baseline trained with ReLU to that using GELU as described in this paper ([arXiv:1606.08415v4](https://arxiv.org/pdf/1606.08415v4.pdf)) & Swish described in this paper ([arXiv:1710.05941v1](https://arxiv.org/pdf/1710.05941v1.pdf)). Note that GELU (Gaussian Error Linear Units) are what GPT-2 and GPT-J are using instead of ReLU.   See you get better convergence or better loss during training and if any of the translations in your tests have changed. Both GELU and Swish are provided by Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GELU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies             37.39%\n",
      "losses               0.692861\n",
      "total_time_in_min        39.2\n",
      "Name: gelu, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(metrics_df['gelu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gelu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>you should pay for it.</th>\n",
       "      <td>Deberías pagar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we have no extra money.</th>\n",
       "      <td>No tenemos dinero a María.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is a problem to deal with.</th>\n",
       "      <td>Este es un problema para eso.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is a really powerful method!</th>\n",
       "      <td>¡Es realmente un estado poderoso!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is an interesting course about Natural Language Processing</th>\n",
       "      <td>Esto es una gustaría cantar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jerry liked to look at paintings while eating garlic ice cream.</th>\n",
       "      <td>El aire es como los días les gusta comer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The irony of the situation wasn't lost on anyone in the room.</th>\n",
       "      <td>La piel estaba a la habitación en la habitación.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facebook plans to make a dramatic break with its past by rebranding the company next week, according to a report.</th>\n",
       "      <td>Un planes iba a tomar una vez por un mes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhone assembler Foxconn has revealed three prototype electric vehicles as part of its effort to become a major player in the automotive industry. \"Our biggest challenge is we don’t know how to make cars,\" Foxconn chairman Young Liu said at the event held Monday.</th>\n",
       "      <td>No tenemos ni ni una manera como tres es una t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 gelu\n",
       "you should pay for it.                                                                Deberías pagar.\n",
       "we have no extra money.                                                    No tenemos dinero a María.\n",
       "This is a problem to deal with.                                         Este es un problema para eso.\n",
       "This is a really powerful method!                                   ¡Es realmente un estado poderoso!\n",
       "This is an interesting course about Natural Lan...                       Esto es una gustaría cantar.\n",
       "Jerry liked to look at paintings while eating g...          El aire es como los días les gusta comer.\n",
       "The irony of the situation wasn't lost on anyon...   La piel estaba a la habitación en la habitación.\n",
       "Facebook plans to make a dramatic break with it...          Un planes iba a tomar una vez por un mes.\n",
       "iPhone assembler Foxconn has revealed three pro...  No tenemos ni ni una manera como tres es una t..."
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob \n",
    "\n",
    "translations = glob.glob('translations/*.json')\n",
    "translations_dict = {}\n",
    "for path in translations:\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        name = path.split('/file-')[-1].split('.json')[0]\n",
    "        translations_dict[name] = data\n",
    "\n",
    "translations_df = pd.DataFrame(translations_dict)\n",
    "pd.DataFrame(translations_df.gelu, index=translations_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies             37.55%\n",
      "losses               0.681648\n",
      "total_time_in_min        38.6\n",
      "Name: swish, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(metrics_df['swish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>you should pay for it.</th>\n",
       "      <td>Deberías pagarlo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we have no extra money.</th>\n",
       "      <td>No tenemos un dinero extra.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is a problem to deal with.</th>\n",
       "      <td>Este problema es un problema de hablar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is a really powerful method!</th>\n",
       "      <td>¡Esto es un hombre realmente poderoso!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is an interesting course about Natural Language Processing</th>\n",
       "      <td>Esta es una buena tipo de 9.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jerry liked to look at paintings while eating garlic ice cream.</th>\n",
       "      <td>El aire se puso a Mary le gusta comer cara en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The irony of the situation wasn't lost on anyone in the room.</th>\n",
       "      <td>La sala no se quedó en la cuarto de la ley.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facebook plans to make a dramatic break with its past by rebranding the company next week, according to a report.</th>\n",
       "      <td>Necesito vivir con su lugar de la noche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhone assembler Foxconn has revealed three prototype electric vehicles as part of its effort to become a major player in the automotive industry. \"Our biggest challenge is we don’t know how to make cars,\" Foxconn chairman Young Liu said at the event held Monday.</th>\n",
       "      <td>No queda una buena parte.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                swish\n",
       "you should pay for it.                                                              Deberías pagarlo.\n",
       "we have no extra money.                                                   No tenemos un dinero extra.\n",
       "This is a problem to deal with.                               Este problema es un problema de hablar.\n",
       "This is a really powerful method!                              ¡Esto es un hombre realmente poderoso!\n",
       "This is an interesting course about Natural Lan...                       Esta es una buena tipo de 9.\n",
       "Jerry liked to look at paintings while eating g...  El aire se puso a Mary le gusta comer cara en ...\n",
       "The irony of the situation wasn't lost on anyon...        La sala no se quedó en la cuarto de la ley.\n",
       "Facebook plans to make a dramatic break with it...           Necesito vivir con su lugar de la noche.\n",
       "iPhone assembler Foxconn has revealed three pro...                          No queda una buena parte."
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(translations_df.swish, index=translations_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: English --> German\n",
    "\n",
    "- Activation function:\n",
    " ReLu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies             36.30%\n",
      "losses               0.536454\n",
      "total_time_in_min        38.1\n",
      "Name: ger, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>German Model</th>\n",
       "      <th>Google Translate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>you should pay for it.</th>\n",
       "      <td>Wir sollten es bezahlen.</td>\n",
       "      <td>We should pay for it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we have no extra money.</th>\n",
       "      <td>Wir haben kein Geld dabei.</td>\n",
       "      <td>We don't have any money with us.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is a problem to deal with.</th>\n",
       "      <td>Das ist ein Jahr mit einem Lachen.</td>\n",
       "      <td>This is a year with a laugh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is a really powerful method!</th>\n",
       "      <td>Das ist eine sehr warm von mir!</td>\n",
       "      <td>That's a very warm one from me!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This is an interesting course about Natural Language Processing</th>\n",
       "      <td>Das ist eine schwierige Angelegenheit.</td>\n",
       "      <td>It is a difficult matter.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jerry liked to look at paintings while eating garlic ice cream.</th>\n",
       "      <td>Ein Junge fing sich wie zu essen.</td>\n",
       "      <td>A boy began to feel like eating.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The irony of the situation wasn't lost on anyone in the room.</th>\n",
       "      <td>Der Raum war nicht in den Gesicht.</td>\n",
       "      <td>The room was not in the face.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facebook plans to make a dramatic break with its past by rebranding the company next week, according to a report.</th>\n",
       "      <td>Einen Plan Plan reden!</td>\n",
       "      <td>Talk a plan plan!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhone assembler Foxconn has revealed three prototype electric vehicles as part of its effort to become a major player in the automotive industry. \"Our biggest challenge is we don’t know how to make cars,\" Foxconn chairman Young Liu said at the event held Monday.</th>\n",
       "      <td>Wir wollen nichts auf den Weg essen.</td>\n",
       "      <td>We don't want to eat anything on the way.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              German Model  \\\n",
       "you should pay for it.                                            Wir sollten es bezahlen.   \n",
       "we have no extra money.                                         Wir haben kein Geld dabei.   \n",
       "This is a problem to deal with.                         Das ist ein Jahr mit einem Lachen.   \n",
       "This is a really powerful method!                          Das ist eine sehr warm von mir!   \n",
       "This is an interesting course about Natural Lan...  Das ist eine schwierige Angelegenheit.   \n",
       "Jerry liked to look at paintings while eating g...       Ein Junge fing sich wie zu essen.   \n",
       "The irony of the situation wasn't lost on anyon...      Der Raum war nicht in den Gesicht.   \n",
       "Facebook plans to make a dramatic break with it...                  Einen Plan Plan reden!   \n",
       "iPhone assembler Foxconn has revealed three pro...    Wir wollen nichts auf den Weg essen.   \n",
       "\n",
       "                                                                             Google Translate  \n",
       "you should pay for it.                                                  We should pay for it.  \n",
       "we have no extra money.                                      We don't have any money with us.  \n",
       "This is a problem to deal with.                                  This is a year with a laugh.  \n",
       "This is a really powerful method!                             That's a very warm one from me!  \n",
       "This is an interesting course about Natural Lan...                  It is a difficult matter.  \n",
       "Jerry liked to look at paintings while eating g...           A boy began to feel like eating.  \n",
       "The irony of the situation wasn't lost on anyon...              The room was not in the face.  \n",
       "Facebook plans to make a dramatic break with it...                          Talk a plan plan!  \n",
       "iPhone assembler Foxconn has revealed three pro...  We don't want to eat anything on the way.  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_translate = [\"We should pay for it.\", \"We don't have any money with us.\", \"This is a year with a laugh.\", \"That's a very warm one from me!\", \"It is a difficult matter.\", \"A boy began to feel like eating.\", \"The room was not in the face.\", \"Talk a plan plan!\", \"We don't want to eat anything on the way.\"]\n",
    "print(metrics_df['ger'])\n",
    "# pd.DataFrame(data=[translations_df.ger, pd.Series(google_translate)], index=translations_df.index) \n",
    "df = pd.DataFrame(translations_df['ger'], index=translations_df.index).join(pd.Series(google_translate, name='translate', index=translations_df.index))\n",
    "df.columns = ['German Model', 'Google Translate']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Summary\n",
    "\n",
    "There wasn't much variability in the metrics for each model besides the effects on changing the depth of the model. Furthermore, the best performing model was a simpler version of the baseline model, with a depth = 2, which also trained much faster than the rest of the models.\n",
    "\n",
    "It's interesting to see what could bring to the table having a much bigger dataset, given that the \"Attention is all you need\" used a more complex model than what I show in my experiments. \n",
    "\n",
    "There's also interesting to note the effect that a new epoch brings to the accuracy of the model. The plots below will show that for the last epochs (almost all of them, except the first ones), the accuracy will start higher, and then it will decrease in each step, increasing again when a new epoch starts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-base.png?raw=true)\n",
    "### Depth 2\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-depth-2.png?raw=true)\n",
    "### Depth 6\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-depth-6.png?raw=true)\n",
    "### Depth 10\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-depth-10.png?raw=true)\n",
    "### Dimension 256\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-dim-256.png?raw=true)\n",
    "### Dimension 1024\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-dim-1024.png?raw=true)\n",
    "### Dimension 2048\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-dim-2048.png?raw=true)\n",
    "### 2 Heads\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-heads-2.png?raw=true)\n",
    "### 4 Heads\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-heads-4.png?raw=true)\n",
    "### 16 Heads\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-heads-16.png?raw=true)\n",
    "### Skipping positional encoding\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-skip-positional.png?raw=true)\n",
    "### Swish Activation\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-swish.png?raw=true)\n",
    "### Gelu Activation\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-gelu.png?raw=true)\n",
    "### Half-sized vocabulary\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-vocab.png?raw=true)\n",
    "### German Vocabulary\n",
    "![](https://github.com/sbarrios93/35200-Deep-Learning-Systems/blob/main/hw-3/images/fig-ger.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a47990de418dedd5e5850a5cbe3fff5766d2f22f31c561e10b2c29272688762b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf-ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
